#!/usr/bin/env node

/**
 * V2 Pipeline Integration Test
 * æµ‹è¯•V2æœåŠ¡å™¨ä¸V1æµæ°´çº¿çš„é›†æˆ
 */

import { RouteCodexServerV2 } from './dist/server-v2/core/route-codex-server-v2.js';

const TEST_CONFIG = {
  server: {
    port: 5509,
    host: '127.0.0.1',
    timeout: 30000,
    useV2: true
  },
  logging: {
    level: 'debug',
    enableConsole: true,
    enableFile: false
  },
  providers: {
    'test-provider': {
      enabled: true,
      models: {
        'glm-4-flash': {
          maxTokens: 4096,
          temperature: 0.7
        }
      }
    }
  },
  v2Config: {
    enableHooks: true,
    hookStages: ['server-entry', 'server-pre-process', 'server-post-process', 'server-response', 'server-final']
  }
};

async function testV2PipelineIntegration() {
  console.log('ğŸ§ª Testing V2 Server with V1 Pipeline Integration...');

  try {
    // åˆ›å»ºV2æœåŠ¡å™¨å®ä¾‹
    const serverV2 = new RouteCodexServerV2(TEST_CONFIG);

    console.log('âœ… V2 Server instance created successfully');

    // æµ‹è¯•åˆå§‹åŒ–
    console.log('ğŸ”§ Initializing V2 Server...');
    await serverV2.initialize();
    console.log('âœ… V2 Server initialized successfully');

    // æ£€æŸ¥çŠ¶æ€
    console.log('ğŸ“Š Server Status:', {
      initialized: serverV2.isInitialized(),
      running: serverV2.isRunning()
    });

    // å¯åŠ¨æœåŠ¡å™¨
    console.log('ğŸš€ Starting V2 Server...');
    await serverV2.start();
    console.log('âœ… V2 Server started successfully');

    // ç­‰å¾…æœåŠ¡å™¨å®Œå…¨å¯åŠ¨
    await new Promise(resolve => setTimeout(resolve, 3000));

    // æµ‹è¯•å¥åº·æ£€æŸ¥
    console.log('ğŸ¥ Testing health check...');
    const healthResponse = await fetch('http://127.0.0.1:5509/health-v2');
    const healthData = await healthResponse.json();
    console.log('âœ… Health check response:', healthData);

    // æµ‹è¯•V2ç«¯ç‚¹ä¸Pipelineé›†æˆ
    console.log('ğŸ”Œ Testing V2 chat completions with Pipeline integration...');
    const chatResponse = await fetch('http://127.0.0.1:5509/v2/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'glm-4-flash',
        messages: [{ role: 'user', content: 'Test V2 with V1 pipeline integration' }],
        stream: false
      })
    });

    if (chatResponse.ok) {
      const chatData = await chatResponse.json();
      console.log('âœ… V2 Chat completions with Pipeline response:', {
        id: chatData.id,
        model: chatData.model,
        hasServerV2Enhanced: !!chatData.serverV2Enhanced,
        hasProcessingTime: !!chatData.processingTime,
        responseKeys: Object.keys(chatData)
      });

      // æ£€æŸ¥æ˜¯å¦é€šè¿‡Pipelineå¤„ç†
      if (chatData.serverV2Enhanced && chatData.processingTime) {
        console.log('âœ… V2 Pipeline integration appears to be working!');
        console.log('ğŸ“‹ Processing time:', `${chatData.processingTime}ms`);
      } else {
        console.log('âš ï¸  V2 Pipeline integration may have issues');
      }

      // æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«Pipelineç‰¹æœ‰çš„å­—æ®µ
      if (chatData.choices && chatData.choices.length > 0) {
        console.log('âœ… Response format matches OpenAI standard');
        console.log('ğŸ“ Response content preview:',
          chatData.choices[0].message?.content?.substring(0, 100) + '...');
      }

    } else {
      console.error('âŒ V2 Chat completions failed:', chatResponse.status, chatResponse.statusText);

      // è¯»å–é”™è¯¯å“åº”
      const errorData = await chatResponse.text();
      console.error('Error response:', errorData);
    }

    // åœæ­¢æœåŠ¡å™¨
    console.log('ğŸ›‘ Stopping V2 Server...');
    await serverV2.stop();
    console.log('âœ… V2 Server stopped successfully');

    console.log('ğŸ‰ V2 Pipeline Integration Test completed successfully!');

  } catch (error) {
    console.error('âŒ V2 Pipeline Integration Test failed:', error);
    process.exit(1);
  }
}

// è¿è¡Œæµ‹è¯•
testV2PipelineIntegration().catch(console.error);