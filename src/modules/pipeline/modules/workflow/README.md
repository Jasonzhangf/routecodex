# Workflow æ¨¡å—

Workflow æ¨¡å—æä¾›æ™ºèƒ½æµå¼æ§åˆ¶åŠŸèƒ½ï¼Œå¤„ç†æµå¼ï¼ˆstreamingï¼‰å’Œéæµå¼ï¼ˆnon-streamingï¼‰è¯·æ±‚ä¹‹é—´çš„è½¬æ¢ï¼Œæ”¯æŒè¯·æ±‚ç¼“å†²ã€å“åº”ç®¡ç†å’Œå¤šç§æµå¼åè®®é€‚é…ã€‚

## ğŸ¯ æ¨¡å—æ¦‚è¿°

Workflow æ¨¡å—æ˜¯æµæ°´çº¿æ¶æ„çš„ç¬¬ 2 å±‚ï¼Œä½äº LLMSwitch å’Œ Compatibility ä¹‹é—´ï¼Œè´Ÿè´£æ§åˆ¶æµå¼è¯·æ±‚çš„å¤„ç†æ–¹å¼ã€‚å®ƒä¸ä»…å¤„ç†ä¼ ç»Ÿçš„æµå¼/éæµå¼è½¬æ¢ï¼Œè¿˜æ”¯æŒ **Responses API æµå¼äº‹ä»¶å¤„ç†**ï¼Œç¡®ä¿ä¸åŒåè®®é—´çš„æµå¼å“åº”éƒ½èƒ½æ­£ç¡®è½¬æ¢å’Œç®¡ç†ã€‚

### ğŸ“‹ æ ¸å¿ƒèŒè´£
- **æµå¼è½¬æ¢**: æµå¼ â†” éæµå¼è¯·æ±‚çš„æ™ºèƒ½è½¬æ¢
- **åè®®é€‚é…**: æ”¯æŒ Chat å’Œ Responses API çš„ä¸åŒæµå¼æ ¼å¼
- **äº‹ä»¶å¤„ç†**: Server-Sent Events (SSE) çš„è§„èŒƒåŒ–å¤„ç†
- **ç¼“å†²ç®¡ç†**: æµå¼æ•°æ®çš„æ™ºèƒ½ç¼“å†²å’Œåˆ†å—
- **å“åº”é‡å»º**: å°†åˆ†å—å“åº”é‡å»ºæˆå®Œæ•´å“åº”æ ¼å¼

## ğŸ”„ æ”¯æŒçš„æµå¼è½¬æ¢

### ğŸ“¡ ä¼ ç»Ÿæµå¼æ§åˆ¶
- **å®ç°æ–‡ä»¶**: `streaming-control.ts`
- **åŠŸèƒ½**: Chat Completions API çš„æµå¼è½¬æ¢
- **ç‰¹æ€§**:
  - æµå¼è¯·æ±‚ â†’ éæµå¼å‘é€ç»™ä¾›åº”å•†
  - éæµå¼å“åº” â†’ ä¿æŒéæµå¼è¿”å›å®¢æˆ·ç«¯
  - æµå¼å‚æ•°å¤„ç†å’Œä¿å­˜
  - é”™è¯¯è¾¹ç•Œå¤„ç†å’Œæ¢å¤

### ğŸ†• Responses æµå¼å¤„ç†
- **å®ç°æ–‡ä»¶**: `responses-streaming-workflow.ts`
- **åŠŸèƒ½**: Responses API çš„æµå¼äº‹ä»¶å¤„ç†
- **ç‰¹æ€§**:
  - **SSE äº‹ä»¶è§£æ**: è§£æ `response.output_text.delta` ç­‰äº‹ä»¶
  - **å“åº”é‡å»º**: å°†åˆ†å—äº‹ä»¶é‡å»ºæˆå®Œæ•´ Responses æ ¼å¼
  - **å…ƒæ•°æ®å¤„ç†**: å¤„ç†äº‹ä»¶å…ƒæ•°æ®å’Œåºåˆ—å·
  - **å·¥å…·è°ƒç”¨æ”¯æŒ**: å¤„ç† `response.tool_call.delta` äº‹ä»¶
  - **å¤šæ¨¡æ€å¤„ç†**: æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€å·¥å…·è°ƒç”¨çš„æ··åˆæµå¼å†…å®¹

## ğŸŒŸ æ ¸å¿ƒåŠŸèƒ½

### ğŸ”„ Chat æµå¼è½¬æ¢æ§åˆ¶
```typescript
// å¤„ç†ä¼ ç»Ÿæµå¼è¯·æ±‚
if (request.stream) {
  converted._originalStream = request.stream;
  converted.stream = false;  // å¼ºåˆ¶éæµå¼å‘é€
}

// ä¿å­˜æµå¼é€‰é¡¹
if (request.stream_options) {
  converted._originalStreamOptions = request.stream_options;
  delete converted.stream_options;
}
```

### ğŸ“¡ Responses æµå¼äº‹ä»¶å¤„ç†
```typescript
// å¤„ç† Responses æµå¼äº‹ä»¶
const processedEvents = await this.processResponseEvents(events);
const rebuiltResponse = this.rebuildResponsesResponse(processedEvents);

return {
  ...rebuiltResponse,
  _streamingEvents: processedEvents,
  _originalProtocol: 'responses'
};
```

### ğŸ›¡ï¸ é”™è¯¯è¾¹ç•Œå¤„ç†
```typescript
// æ™ºèƒ½é”™è¯¯å¤„ç†
try {
  const result = await this.processStreamingRequest(request);
} catch (error) {
  if (this.isStreamingRequest(request)) {
    return this.createStreamingErrorResponse(error, request._protocol);
  }
  throw this.createStandardErrorResponse(error);
}
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
src/modules/pipeline/modules/workflow/
â”œâ”€â”€ streaming-control.ts              # ä¼ ç»Ÿæµå¼æ§åˆ¶å®ç°
â”œâ”€â”€ responses-streaming-workflow.ts   # Responses æµå¼å¤„ç†å®ç° â­
â”œâ”€â”€ streaming-event-processor.ts      # æµå¼äº‹ä»¶å¤„ç†å·¥å…·
â”œâ”€â”€ response-rebuilder.ts             # å“åº”é‡å»ºå·¥å…·
â””â”€â”€ README.md                         # æœ¬æ–‡æ¡£
```

## ğŸ”„ å·¥ä½œæµç±»å‹è¯¦è§£

### ğŸ“¡ ä¼ ç»Ÿæµå¼æ§åˆ¶ (StreamingControlWorkflow)
```typescript
export class StreamingControlWorkflow implements WorkflowModule {
  readonly type = 'streaming-control';
  readonly workflowType = 'streaming-converter';

  async processIncoming(request: any): Promise<any> {
    // Chat Completions æµå¼è½¬æ¢é€»è¾‘
    if (request.stream) {
      return this.convertStreamingToNonStreaming(request);
    }
    return request;
  }

  async processStreamingControl(request: any): Promise<any> {
    // ä¸“é—¨çš„æµå¼æ§åˆ¶å¤„ç†
    return this.handleStreamingControl(request);
  }
}
```

### ğŸ†• Responses æµå¼å¤„ç† (ResponsesStreamingWorkflow)
```typescript
export class ResponsesStreamingWorkflow implements WorkflowModule {
  readonly type = 'responses-streaming-workflow';
  readonly workflowType = 'responses-event-processor';

  async processIncoming(request: any): Promise<any> {
    // Responses API æµå¼äº‹ä»¶å¤„ç†
    if (request._protocol === 'responses' && request._hasStreamingEvents) {
      return this.processResponsesStreamingEvents(request);
    }
    return request;
  }

  private async processResponsesStreamingEvents(request: any): Promise<any> {
    // å¤„ç† SSE äº‹ä»¶æµ
    const events = this.extractStreamingEvents(request);
    const processedEvents = await this.processResponseEvents(events);

    // é‡å»ºå®Œæ•´ Responses å“åº”
    return this.rebuildResponsesResponse(processedEvents);
  }
}
```

### ğŸ”„ æµå¼åˆ°éæµå¼è½¬æ¢
```typescript
private convertStreamingToNonStreaming(request: any): any {
  const converted = { ...request };

  // ä¿å­˜åŸå§‹æµå¼è®¾ç½®
  if (request.stream) {
    converted._originalStream = request.stream;
    converted.stream = false;  // å¼ºåˆ¶éæµå¼
  }

  // å¤„ç†æµå¼é€‰é¡¹
  if (request.stream_options) {
    converted._originalStreamOptions = request.stream_options;
    delete converted.stream_options;
  }

  return converted;
}
```

### ğŸ“¡ Responses äº‹ä»¶å¤„ç†
```typescript
private async processResponseEvents(events: StreamingEvent[]): Promise<ProcessedEvent[]> {
  const processedEvents: ProcessedEvent[] = [];

  for (const event of events) {
    switch (event.type) {
      case 'response.output_text.delta':
        processedEvents.push(this.processTextDeltaEvent(event));
        break;
      case 'response.tool_call.delta':
        processedEvents.push(this.processToolCallDeltaEvent(event));
        break;
      case 'response.done':
        processedEvents.push(this.processCompletionEvent(event));
        break;
    }
  }

  return processedEvents;
}

private rebuildResponsesResponse(events: ProcessedEvent[]): ResponsesResponse {
  const outputText = this.rebuildOutputText(events);
  const toolCalls = this.rebuildToolCalls(events);
  const metadata = this.extractMetadata(events);

  return {
    id: metadata.responseId,
    status: 'completed',
    output: [{
      type: 'message',
      role: 'assistant',
      content: [
        { type: 'input_text', text: outputText },
        ...toolCalls
      ]
    }],
    usage: metadata.usage,
    _streamingEvents: events
  };
}
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### ä¼ ç»Ÿæµå¼æ§åˆ¶ä½¿ç”¨
```typescript
import { StreamingControlWorkflow } from './streaming-control.js';

const workflow = new StreamingControlWorkflow({
  type: 'streaming-control',
  config: {
    streamingToNonStreaming: true,
    nonStreamingToStreaming: false  // å½“å‰æœªå®ç°
  }
}, dependencies);

await workflow.initialize();

// å¤„ç†æµå¼è¯·æ±‚
const streamingRequest = {
  model: 'gpt-4',
  messages: [{ role: 'user', content: 'Hello' }],
  stream: true,
  stream_options: {
    include_usage: true
  }
};

const convertedRequest = await workflow.processIncoming(streamingRequest);
// ç»“æœ: { model: 'gpt-4', messages: [...], stream: false, _originalStream: true }
```

### Responses æµå¼å¤„ç†ä½¿ç”¨
```typescript
import { ResponsesStreamingWorkflow } from './responses-streaming-workflow.js';

const responsesWorkflow = new ResponsesStreamingWorkflow({
  type: 'responses-streaming-workflow',
  config: {
    enableEventProcessing: true,
    rebuildCompleteResponse: true
  }
}, dependencies);

await responsesWorkflow.initialize();

// å¤„ç† Responses æµå¼äº‹ä»¶
const responsesEventsRequest = {
  _protocol: 'responses',
  _hasStreamingEvents: true,
  streamingEvents: [
    { type: 'response.output_text.delta', data: { delta: 'Hello' } },
    { type: 'response.output_text.delta', data: { delta: ' world!' } },
    { type: 'response.done', data: { usage: { total_tokens: 10 } } }
  ]
};

const rebuiltResponse = await responsesWorkflow.processIncoming(responsesEventsRequest);
// ç»“æœ: å®Œæ•´çš„ Responses API å“åº”æ ¼å¼
```

### åœ¨æµæ°´çº¿é…ç½®ä¸­ä½¿ç”¨
```typescript
const pipelineConfig = {
  modules: {
    llmSwitch: {
      type: 'llmswitch-response-chat',  // Responses åè®®æ”¯æŒ
      config: { enableValidation: true }
    },
    workflow: {
      type: 'responses-streaming-workflow',  // Responses æµå¼å¤„ç†
      config: { enableEventProcessing: true }
    },
    compatibility: {
      type: 'passthrough-compatibility',
      config: {}
    },
    provider: {
      type: 'lmstudio-http',
      config: { baseUrl: 'http://localhost:1234' }
    }
  }
};

// å®Œæ•´çš„ Responses API æµå¼è¯·æ±‚å¤„ç†æµç¨‹
const request = {
  model: 'gpt-4',
  instructions: 'You are a helpful assistant.',
  input: [
    {
      type: 'message',
      role: 'user',
      content: [{ type: 'input_text', text: 'Hello!' }]
    }
  ],
  stream: true  // æµå¼è¯·æ±‚
};

// ç»è¿‡æµæ°´çº¿å¤„ç†ï¼š
// 1. LLM Switch: Responses â†’ Chat è½¬æ¢
// 2. Workflow: æµå¼æ§åˆ¶å¤„ç†
// 3. Compatibility: æ ¼å¼é€‚é…
// 4. Provider: å‘é€ç»™ä¾›åº”å•†
```

## âš™ï¸ é…ç½®é€‰é¡¹

### ğŸ“¡ ä¼ ç»Ÿæµå¼æ§åˆ¶é…ç½®
```typescript
interface StreamingControlConfig {
  streamingToNonStreaming?: boolean;    // æµå¼è½¬éæµå¼ (é»˜è®¤: true)
  nonStreamingToStreaming?: boolean;    // éæµå¼è½¬æµå¼ (é»˜è®¤: falseï¼Œæœªå®ç°)
  bufferSize?: number;                  // ç¼“å†²åŒºå¤§å°
  chunkSize?: number;                   // æ•°æ®å—å¤§å°
  timeout?: number;                     // è¶…æ—¶æ—¶é—´
  preserveStreamOptions?: boolean;      // ä¿ç•™æµå¼é€‰é¡¹
}
```

### ğŸ†• Responses æµå¼å¤„ç†é…ç½®
```typescript
interface ResponsesStreamingConfig {
  enableEventProcessing?: boolean;      // å¯ç”¨äº‹ä»¶å¤„ç†
  rebuildCompleteResponse?: boolean;    // é‡å»ºå®Œæ•´å“åº”
  eventTimeout?: number;                // äº‹ä»¶å¤„ç†è¶…æ—¶
  maxEventBufferSize?: number;          // æœ€å¤§äº‹ä»¶ç¼“å†²åŒº
  preserveEventOrder?: boolean;         // ä¿æŒäº‹ä»¶é¡ºåº
  enableMetrics?: boolean;              // å¯ç”¨æ€§èƒ½æŒ‡æ ‡
}
```

### é»˜è®¤é…ç½®
```typescript
const defaultStreamingConfig = {
  streamingToNonStreaming: true,      // å¯ç”¨æµå¼åˆ°éæµå¼è½¬æ¢
  nonStreamingToStreaming: false,     // ç¦ç”¨éæµå¼åˆ°æµå¼è½¬æ¢
  bufferSize: 1024,                   // 1KB ç¼“å†²åŒº
  chunkSize: 512,                     // 512å­—èŠ‚æ•°æ®å—
  timeout: 30000,                     // 30ç§’è¶…æ—¶
  preserveStreamOptions: true         // ä¿ç•™æµå¼é€‰é¡¹
};

const defaultResponsesConfig = {
  enableEventProcessing: true,        // å¯ç”¨äº‹ä»¶å¤„ç†
  rebuildCompleteResponse: true,      // é‡å»ºå®Œæ•´å“åº”
  eventTimeout: 60000,                // 60ç§’äº‹ä»¶è¶…æ—¶
  maxEventBufferSize: 1000,           // æœ€å¤§1000ä¸ªäº‹ä»¶
  preserveEventOrder: true,           // ä¿æŒäº‹ä»¶é¡ºåº
  enableMetrics: true                 // å¯ç”¨æ€§èƒ½æŒ‡æ ‡
};
```

## ğŸ“Š æµå¼å‚æ•°å¤„ç†

### ğŸ“¡ Chat æµå¼å‚æ•°
```typescript
// OpenAI Chat Completions æµå¼å‚æ•°
interface ChatStreamOptions {
  stream?: boolean;                   // å¯ç”¨æµå¼å“åº”
  stream_options?: {
    include_usage?: boolean;          // åŒ…å«ä½¿ç”¨ç»Ÿè®¡
    chunk_size?: number;              // æ•°æ®å—å¤§å°
  };
}

// å¤„ç†åçš„æµå¼å‚æ•°
interface ProcessedChatStreamOptions {
  _originalStream?: boolean;          // åŸå§‹æµå¼è®¾ç½®
  _originalStreamOptions?: ChatStreamOptions; // åŸå§‹æµå¼é€‰é¡¹
  _isStreaming?: boolean;             // æ ‡è®°ä¸ºæµå¼è¯·æ±‚
}
```

### ğŸ†• Responses æµå¼å‚æ•°
```typescript
// OpenAI Responses API æµå¼å‚æ•°
interface ResponsesStreamOptions {
  stream?: boolean;                   // å¯ç”¨æµå¼å“åº”
  tools?: any[];                      // å·¥å…·å®šä¹‰
  tool_choice?: any;                  // å·¥å…·é€‰æ‹©
  max_output_tokens?: number;         // æœ€å¤§è¾“å‡ºä»¤ç‰Œ
}

// Responses æµå¼äº‹ä»¶ç»“æ„
interface ResponsesStreamingEvent {
  type: string;                       // äº‹ä»¶ç±»å‹
  data: any;                          // äº‹ä»¶æ•°æ®
  timestamp?: number;                 // æ—¶é—´æˆ³
  sequence_number?: number;           // åºåˆ—å·
  item_id?: string;                   // é¡¹ç›®ID
}

// å¤„ç†åçš„ Responses å‚æ•°
interface ProcessedResponsesStreamOptions {
  _protocol: 'responses';             // åè®®æ ‡è¯†
  _hasStreamingEvents?: boolean;      // æ˜¯å¦åŒ…å«æµå¼äº‹ä»¶
  _streamingEvents?: ResponsesStreamingEvent[]; // æµå¼äº‹ä»¶æ•°ç»„
  _originalStreamOptions?: ResponsesStreamOptions; // åŸå§‹æµå¼é€‰é¡¹
}
```

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†

### å¤šå±‚é”™è¯¯å¤„ç†
```typescript
// æ™ºèƒ½é”™è¯¯å¤„ç†ç­–ç•¥
try {
  const result = await this.processStreamingRequest(request);
} catch (error) {
  // æ ¹æ®åè®®ç±»å‹é€‰æ‹©é”™è¯¯å¤„ç†æ–¹å¼
  if (request._protocol === 'responses') {
    return this.createResponsesErrorResponse(error);
  } else if (request._originalStream) {
    return this.createStreamingErrorResponse(error);
  }
  throw this.createStandardErrorResponse(error);
}

// Responses API é”™è¯¯å“åº”
private createResponsesErrorResponse(error: any): ResponsesError {
  return {
    id: `error_${Date.now()}`,
    type: 'error',
    error: {
      type: 'invalid_request_error',
      message: error.message,
      code: 'streaming_processing_error'
    },
    _protocol: 'responses',
    _errorContext: {
      workflowType: this.type,
      timestamp: Date.now()
    }
  };
}

// Chat æµå¼é”™è¯¯å“åº”
private createStreamingErrorResponse(error: any): StreamingError {
  return {
    id: `error_${Date.now()}`,
    object: 'chat.completion.chunk',
    created: Math.floor(Date.now() / 1000),
    model: 'error-model',
    choices: [{
      index: 0,
      delta: { role: 'assistant', content: `Error: ${error.message}` },
      finish_reason: 'error'
    }],
    _errorContext: {
      originalError: error.message,
      workflowType: this.type
    }
  };
}
```

### è¯¦ç»†é”™è¯¯æ—¥å¿—
```typescript
// åˆ†å±‚é”™è¯¯æ—¥å¿—è®°å½•
this.logger.logModule(this.id, 'workflow-error', {
  error: error instanceof Error ? error.message : String(error),
  protocol: request._protocol || 'unknown',
  requestType: this.inferRequestType(request),
  hasStreamingEvents: !!request._hasStreamingEvents,
  originalStream: !!request._originalStream,
  errorContext: {
    workflowType: this.type,
    timestamp: Date.now(),
    stack: error.stack
  }
});
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ç®¡ç†ç­–ç•¥
```typescript
// æµå¼æ•°æ®å†…å­˜ç®¡ç†
class StreamingEventBuffer {
  private events: ResponsesStreamingEvent[] = [];
  private maxBufferSize: number;

  constructor(maxSize: number = 1000) {
    this.maxBufferSize = maxSize;
  }

  addEvent(event: ResponsesStreamingEvent): void {
    // æ·»åŠ äº‹ä»¶å¹¶ç®¡ç†å†…å­˜
    this.events.push(event);

    // é˜²æ­¢å†…å­˜æ³„æ¼
    if (this.events.length > this.maxBufferSize) {
      this.events.shift(); // ç§»é™¤æœ€æ—§çš„äº‹ä»¶
    }
  }

  getEvents(): ResponsesStreamingEvent[] {
    return [...this.events]; // è¿”å›å‰¯æœ¬é¿å…å¤–éƒ¨ä¿®æ”¹
  }
}
```

### å¼‚æ­¥äº‹ä»¶å¤„ç†
```typescript
// å¼‚æ­¥å¤„ç†æµå¼äº‹ä»¶é¿å…é˜»å¡
async processStreamingEventsAsync(events: ResponsesStreamingEvent[]): Promise<ProcessedEvent[]> {
  const batches = this.createEventBatches(events);
  const processedBatches = await Promise.all(
    batches.map(batch => this.processEventBatch(batch))
  );

  return processedBatches.flat();
}

// äº‹ä»¶æ‰¹å¤„ç†
private createEventBatches(events: ResponsesStreamingEvent[], batchSize: number = 50): ResponsesStreamingEvent[][] {
  const batches: ResponsesStreamingEvent[][] = [];
  for (let i = 0; i < events.length; i += batchSize) {
    batches.push(events.slice(i, i + batchSize));
  }
  return batches;
}
```

## ğŸ” è°ƒè¯•æ”¯æŒ

### æµå¼å¤„ç†è°ƒè¯•
```typescript
// è¯¦ç»†çš„æµå¼å¤„ç†æ—¥å¿—
this.logger.logModule(this.id, 'streaming-processing-start', {
  protocol: request._protocol,
  hasStreamingEvents: !!request._hasStreamingEvents,
  eventCount: request._streamingEvents?.length || 0,
  originalStream: !!request._originalStream
});

// äº‹ä»¶å¤„ç†è¿›åº¦
this.logger.logModule(this.id, 'event-processing-progress', {
  processedEvents: processedCount,
  totalEvents: totalEvents,
  percentage: Math.round((processedCount / totalEvents) * 100),
  processingTime: Date.now() - startTime
});

// å“åº”é‡å»ºå®Œæˆ
this.logger.logModule(this.id, 'response-rebuild-complete', {
  rebuiltResponseId: response.id,
  outputLength: response.output?.[0]?.content?.[0]?.text?.length || 0,
  toolCallCount: response.output?.[0]?.content?.filter(c => c.type === 'tool_call').length || 0,
  totalProcessingTime: Date.now() - startTime
});
```

### çŠ¶æ€ç›‘æ§
```typescript
// å·¥ä½œæµçŠ¶æ€ç›‘æ§
interface WorkflowStatus {
  id: string;
  type: string;
  workflowType: string;
  isInitialized: boolean;
  config: any;
  metrics?: {
    processedRequests: number;
    streamingRequestsProcessed: number;
    responsesEventsProcessed: number;
    averageProcessingTime: number;
    errorCount: number;
  };
}

// è·å–è¯¦ç»†çŠ¶æ€
getStatus(): WorkflowStatus {
  return {
    id: this.id,
    type: this.type,
    workflowType: this.workflowType,
    isInitialized: this.isInitialized,
    config: this.config,
    metrics: this.metrics?.getMetrics()
  };
}
```

## ğŸŒ åè®®æ”¯æŒçŸ©é˜µ

| åè®®ç±»å‹ | æµå¼æ”¯æŒ | äº‹ä»¶å¤„ç† | å“åº”é‡å»º | å·¥å…·è°ƒç”¨ | çŠ¶æ€ |
|---------|---------|---------|---------|---------|------|
| Chat Completions | âœ… | âœ… | âœ… | âœ… | ç¨³å®š |
| Responses API | âœ… | âœ… | âœ… | âœ… | æ–°å¢ |
| Anthropic | âŒ | âŒ | âŒ | âŒ | è®¡åˆ’ä¸­ |
| Custom | ğŸ”„ | ğŸ”„ | ğŸ”„ | ğŸ”„ | æ‰©å±•ä¸­ |

## ğŸš¨ å·²çŸ¥é™åˆ¶

### ğŸ“¡ å½“å‰é™åˆ¶
1. **Chat æµå¼å“åº”ç”Ÿæˆ** - ä¸å®ç°éæµå¼åˆ°æµå¼çš„è½¬æ¢
2. **å¤šåè®®æ··åˆ** - ä¸æ”¯æŒåŒä¸€è¯·æ±‚ä¸­çš„å¤šç§åè®®æ··åˆ
3. **äº‹ä»¶é¡ºåºä¿è¯** - åœ¨é«˜å¹¶å‘ä¸‹å¯èƒ½å‡ºç°äº‹ä»¶ä¹±åº
4. **å¤§äº‹ä»¶å¤„ç†** - è¶…å¤§æµå¼äº‹ä»¶å¯èƒ½å¯¼è‡´å†…å­˜å‹åŠ›

### ğŸ†• Responses API é™åˆ¶
1. **å¤æ‚å·¥å…·è°ƒç”¨** - å¤æ‚çš„æµå¼å·¥å…·è°ƒç”¨å¤„ç†è¿˜åœ¨ä¼˜åŒ–ä¸­
2. **å¤šæ¨¡æ€æµå¼** - å›¾åƒå’Œè§†é¢‘çš„æµå¼å¤„ç†æ”¯æŒæœ‰é™
3. **é•¿æ–‡æœ¬é‡å»º** - è¶…é•¿å“åº”çš„é‡å»ºæ€§èƒ½éœ€è¦ä¼˜åŒ–
4. **å®æ—¶æ€§** - äº‹ä»¶å¤„ç†å’Œå“åº”é‡å»ºçš„å»¶è¿Ÿé—®é¢˜

### ğŸ”„ æœªæ¥è®¡åˆ’
1. **å®Œæ•´æµå¼æ”¯æŒ** - å®ç°å®Œæ•´çš„åŒå‘æµå¼è½¬æ¢
2. **å¤šåè®®ç»Ÿä¸€** - ç»Ÿä¸€æ‰€æœ‰åè®®çš„æµå¼å¤„ç†é€»è¾‘
3. **å®æ—¶ä¼˜åŒ–** - å‡å°‘äº‹ä»¶å¤„ç†å’Œå“åº”é‡å»ºçš„å»¶è¿Ÿ
4. **æ™ºèƒ½ç¼“å†²** - åŸºäºå†…å®¹ç±»å‹çš„æ™ºèƒ½ç¼“å†²ç­–ç•¥
5. **åè®®æ‰©å±•** - æ”¯æŒæ›´å¤š AI åè®®çš„æµå¼å¤„ç†

## ğŸ”§ æ‰©å±•æ€§

### æ·»åŠ æ–°çš„å·¥ä½œæµç±»å‹
```typescript
// æ–°åè®®å·¥ä½œæµå®ç°
class NewProtocolWorkflow implements WorkflowModule {
  readonly type = 'new-protocol-workflow';
  readonly workflowType = 'new-protocol-processor';

  async processIncoming(request: any): Promise<any> {
    if (request._protocol === 'new-protocol') {
      return this.processNewProtocolStreaming(request);
    }
    return request;
  }

  private async processNewProtocolStreaming(request: any): Promise<any> {
    // å®ç°æ–°åè®®çš„æµå¼å¤„ç†é€»è¾‘
    const events = this.extractNewProtocolEvents(request);
    return this.rebuildNewProtocolResponse(events);
  }
}
```

### è‡ªå®šä¹‰äº‹ä»¶å¤„ç†å™¨
```typescript
// è‡ªå®šä¹‰äº‹ä»¶å¤„ç†å™¨
class CustomEventProcessor {
  async processEvents(events: any[], processor: (event: any) => Promise<any>): Promise<any[]> {
    // è‡ªå®šä¹‰äº‹ä»¶å¤„ç†é€»è¾‘
    const processedEvents = [];

    for (const event of events) {
      try {
        const processed = await processor(event);
        processedEvents.push(processed);
      } catch (error) {
        // é”™è¯¯æ¢å¤ç­–ç•¥
        processedEvents.push(this.createErrorEvent(event, error));
      }
    }

    return processedEvents;
  }
}
```

## ğŸ“ˆ ç‰ˆæœ¬ä¿¡æ¯

- **å½“å‰ç‰ˆæœ¬**: 2.0.0
- **æ–°å¢ç‰¹æ€§**: Responses API æµå¼äº‹ä»¶å¤„ç†ã€æ™ºèƒ½é”™è¯¯æ¢å¤ã€æ€§èƒ½ç›‘æ§
- **å…¼å®¹æ€§**: RouteCodex Pipeline >= 2.0.0
- **TypeScript**: >= 5.0.0
- **Node.js**: >= 18.0.0

## ğŸ”— ä¾èµ–å…³ç³»

- **rcc-debugcenter**: è°ƒè¯•ä¸­å¿ƒé›†æˆ
- **PipelineDebugLogger**: æ¨¡å—æ—¥å¿—è®°å½•
- **ErrorHandlingCenter**: é”™è¯¯å¤„ç†é›†æˆ
- **BaseModule**: åŸºç¡€æ¨¡å—æ¥å£
- **StreamingEventProcessor**: æµå¼äº‹ä»¶å¤„ç†å·¥å…·
- **ResponseRebuilder**: å“åº”é‡å»ºå·¥å…·

## ğŸ”„ æ›´æ–°æ—¥å¿—

### v2.0.0 (2025-10-17)
- âœ¨ æ–°å¢ Responses API æµå¼äº‹ä»¶å¤„ç†æ”¯æŒ
- ğŸ†• å®ç°å®Œæ•´çš„ SSE äº‹ä»¶è§£æå’Œå“åº”é‡å»º
- ğŸ”„ å¢å¼ºçš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
- ğŸ“Š å®Œå–„çš„æ€§èƒ½ç›‘æ§å’Œè°ƒè¯•åŠŸèƒ½
- ğŸ›¡ï¸ æ”¹è¿›çš„å†…å­˜ç®¡ç†å’Œç¼“å†²ç­–ç•¥
- ğŸ“š æ›´æ–°æ–‡æ¡£ï¼Œæ·»åŠ è¯¦ç»†çš„ä½¿ç”¨ç¤ºä¾‹å’Œé…ç½®æŒ‡å—

### v1.5.0 (2025-01-22)
- ğŸ”§ å®Œå–„ä¼ ç»Ÿæµå¼æ§åˆ¶åŠŸèƒ½
- ğŸ“Š å¢åŠ æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•
- ğŸ›¡ï¸ æ”¹è¿›é”™è¯¯å¤„ç†æœºåˆ¶

### v1.0.0 (2025-01-22)
- ğŸ¯ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- ğŸ”„ åŸºç¡€çš„æµå¼æ§åˆ¶åŠŸèƒ½
- ğŸ“Š é…ç½®é©±åŠ¨çš„å·¥ä½œæµå¤„ç†

---

**æœ€åæ›´æ–°**: 2025-10-17 - å…¨é¢æ›´æ–° Workflow æ¨¡å—æ–‡æ¡£ï¼Œæ–°å¢ Responses API æµå¼å¤„ç†æ”¯æŒ