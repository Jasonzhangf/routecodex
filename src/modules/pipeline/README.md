# Pipeline Module

RouteCodexæµæ°´çº¿æ¨¡å—æä¾›å¯ç»„åˆçš„è¯·æ±‚å¤„ç†æµæ°´çº¿ï¼Œæ”¯æŒåè®®è½¬æ¢ã€æµå¼æ§åˆ¶å’ŒProvideré€‚é…ã€‚

## æ¦‚è¿°

æµæ°´çº¿æ¨¡å—æ˜¯RouteCodexç³»ç»Ÿçš„æ ¸å¿ƒè¯·æ±‚å¤„ç†ç»„ä»¶ï¼Œè´Ÿè´£å°†è·¯ç”±åçš„è¯·æ±‚é€šè¿‡é¢„å®šä¹‰çš„å¤„ç†æµæ°´çº¿è½¬æ¢ä¸ºProviderå¯å¤„ç†çš„æ ¼å¼ï¼Œå¹¶å°†å“åº”è½¬æ¢å›å®¢æˆ·ç«¯æœŸæœ›çš„æ ¼å¼ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ”§ æ¨¡å—åŒ–æ¶æ„
- **LLMSwitch**: åè®®è½¬æ¢å±‚ï¼ˆç›®å‰ä¸“æ³¨OpenAIé€ä¼ ï¼‰
- **Workflow**: æµå¼/éæµå¼è½¬æ¢æ§åˆ¶
- **Compatibility**: åè®®å†…å­—æ®µé€‚é…å’Œå·¥å…·è°ƒç”¨è½¬æ¢
- **Provider**: å…·ä½“ä¾›åº”å•†å®ç°ï¼ˆæ”¯æŒQwenã€LM Studioç­‰ï¼‰

### ğŸš€ é¢„åˆ›å»ºæµæ°´çº¿
- åˆå§‹åŒ–æ—¶åˆ›å»ºæ‰€æœ‰éœ€è¦çš„æµæ°´çº¿
- è·¯ç”±æ—¶ç›´æ¥é€‰æ‹©å¯¹åº”æµæ°´çº¿
- é¿å…è¿è¡Œæ—¶åŠ¨æ€åˆ›å»ºå¼€é”€

### ğŸ“‹ é…ç½®é©±åŠ¨
- Provideré…ç½®ä¸­ç›´æ¥æŒ‡å®šCompatibilityè§„åˆ™
- åŸºäºJSONé…ç½®çš„å­—æ®µè½¬æ¢
- ç»Ÿä¸€çš„è½¬æ¢è¡¨æ ¼å¼
- LM Studio Tools APIè‡ªåŠ¨é€‚é…

### ğŸ›¡ï¸ é”™è¯¯å¤„ç†é›†æˆ
- é›†æˆErrorHandlingCenter
- æ— é™é»˜å¤±è´¥ï¼Œæ‰€æœ‰é”™è¯¯éƒ½ä¸ŠæŠ¥
- æ”¯æŒè®¤è¯å¤±è´¥è‡ªåŠ¨æ¢å¤

## æ–‡ä»¶ç»“æ„

```
src/modules/pipeline/
â”œâ”€â”€ index.ts                          # æ¨¡å—å…¥å£
â”œâ”€â”€ README.md                         # æ¨¡å—æ–‡æ¡£
â”œâ”€â”€ core/                             # æ ¸å¿ƒæµæ°´çº¿å®ç°
â”‚   â”œâ”€â”€ base-pipeline.ts              # åŸºç¡€æµæ°´çº¿ç±»
â”‚   â”œâ”€â”€ pipeline-manager.ts           # æµæ°´çº¿ç®¡ç†å™¨
â”‚   â”œâ”€â”€ openai-pipeline.ts            # OpenAIæµæ°´çº¿å®ç°
â”‚   â””â”€â”€ openai-pipeline-factory.ts    # OpenAIæµæ°´çº¿å·¥å‚
â”œâ”€â”€ interfaces/                       # æ¨¡å—æ¥å£å®šä¹‰
â”‚   â”œâ”€â”€ llm-switch-module.ts          # LLMSwitchæ¥å£
â”‚   â”œâ”€â”€ workflow-module.ts            # Workflowæ¥å£
â”‚   â”œâ”€â”€ compatibility-module.ts       # Compatibilityæ¥å£
â”‚   â””â”€â”€ provider-module.ts           # Provideræ¥å£
â”œâ”€â”€ modules/                          # å…·ä½“æ¨¡å—å®ç°
â”‚   â”œâ”€â”€ llm-switch/                   # LLMSwitchå®ç°
â”‚   â”‚   â””â”€â”€ openai-passthrough.ts     # OpenAIé€ä¼ å®ç°
â”‚   â”œâ”€â”€ workflow/                     # Workflowå®ç°
â”‚   â”‚   â””â”€â”€ streaming-control.ts      # æµå¼æ§åˆ¶å®ç°
â”‚   â”œâ”€â”€ compatibility/                # Compatibilityå®ç°
â”‚   â”‚   â”œâ”€â”€ field-mapping.ts          # å­—æ®µæ˜ å°„å®ç°
â”‚   â”‚   â””â”€â”€ lmstudio-compatibility.ts  # LM Studioå…¼å®¹æ€§å¤„ç†
â”‚   â””â”€â”€ providers/                    # Providerå®ç°
â”‚       â”œâ”€â”€ base-provider.ts          # åŸºç¡€Providerç±»
â”‚       â”œâ”€â”€ qwen-http-provider.ts     # Qwen HTTP Provider
â”‚       â”œâ”€â”€ lmstudio-provider.ts      # LM Studio Provider
â”‚       â”œâ”€â”€ generic-http-provider.ts   # é€šç”¨HTTP Provider
â”‚       â””â”€â”€ openai-passthrough.ts     # OpenAIé€ä¼ Provider
â”œâ”€â”€ types/                            # ç±»å‹å®šä¹‰
â”‚   â”œâ”€â”€ pipeline-types.ts             # æµæ°´çº¿ç±»å‹
â”‚   â”œâ”€â”€ transformation-types.ts       # è½¬æ¢ç±»å‹
â”‚   â””â”€â”€ provider-types.ts             # Providerç±»å‹
â”œâ”€â”€ utils/                            # å·¥å…·ç±»
â”‚   â”œâ”€â”€ transformation-engine.ts       # è½¬æ¢å¼•æ“
â”‚   â”œâ”€â”€ error-integration.ts          # é”™è¯¯å¤„ç†é›†æˆ
â”‚   â””â”€â”€ debug-logger.ts              # è°ƒè¯•æ—¥å¿—
â””â”€â”€ config/                           # é…ç½®ç®¡ç†
    â””â”€â”€ pipeline-config-manager.ts    # é…ç½®ç®¡ç†å™¨
```

## æ ¸å¿ƒæ¦‚å¿µ

### æµæ°´çº¿ç»„åˆåŸåˆ™

æºåè®® + ç›®æ ‡Providerå†³å®šäº†æµæ°´çº¿çš„ç»„æˆï¼š

```
æºåè®®: OpenAI + ç›®æ ‡Provider: Qwen =
  LLMSwitch(OpenAIé€ä¼ ) +
  Workflow(æµæ§) +
  Compatibility(Qwené€‚é…) +
  Provider(Qwenå®ç°)

æºåè®®: OpenAI + ç›®æ ‡Provider: LM Studio =
  LLMSwitch(OpenAIé€ä¼ ) +
  Workflow(æµæ§) +
  Compatibility(LM Studio Tools APIé€‚é…) +
  Provider(LM Studioå®ç°)
```

### æ¨¡å—å±‚æ¬¡

1. **LLMSwitchå±‚**: åè®®è½¬æ¢
   - OpenAI â†” OpenAI: é€ä¼ 
   - OpenAI â†” Anthropic: åè®®è½¬æ¢
   - ç›®å‰ä¸“æ³¨OpenAIé€ä¼ 

2. **Workflowå±‚**: æµå¼æ§åˆ¶
   - æµå¼è¯·æ±‚ â†’ éæµå¼å‘é€
   - éæµå¼å“åº” â†’ æµå¼è¿”å›
   - ç¼“å†²ç®¡ç†

3. **Compatibilityå±‚**: å­—æ®µé€‚é…
   - åŸºäºJSONé…ç½®çš„å­—æ®µè½¬æ¢
   - å·¥å…·è°ƒç”¨é€‚é…
   - LM Studio Tools APIè½¬æ¢
   - å“åº”æ ¼å¼è½¬æ¢

4. **Providerå±‚**: æœåŠ¡å®ç°
   - HTTPè¯·æ±‚å¤„ç†
   - è®¤è¯ç®¡ç†
   - é”™è¯¯å¤„ç†
   - LM Studioä¼šè¯ç®¡ç†
   - å·¥å…·è°ƒç”¨æ‰§è¡Œ

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```typescript
import { PipelineManager, OpenAIPipelineFactory } from './pipeline/index.js';

// åˆ›å»ºæµæ°´çº¿ç®¡ç†å™¨
const pipelineManager = new PipelineManager();
await pipelineManager.initialize({
  pipelines: [
    {
      id: 'qwen.qwen3-coder-plus',
      provider: qwenProviderConfig,
      modules: {
        llmSwitch: { type: 'openai-passthrough' },
        workflow: { type: 'streaming-control' },
        compatibility: { type: 'field-mapping' },
        provider: { type: 'qwen-http' }
      }
    }
  ]
});

// é€‰æ‹©æµæ°´çº¿å¤„ç†è¯·æ±‚
const pipeline = pipelineManager.selectPipeline({
  providerId: 'qwen',
  modelId: 'qwen3-coder-plus'
});

const response = await pipeline.processRequest(request);
```

### LM Studioé›†æˆç¤ºä¾‹

LM Studioé›†æˆæ”¯æŒTools APIå’Œå®Œæ•´çš„å·¥å…·è°ƒç”¨åŠŸèƒ½ï¼š

```typescript
// åˆ›å»ºLM Studioæµæ°´çº¿
const lmStudioPipeline = {
  id: 'lmstudio.llama2-7b-chat',
  provider: {
    type: 'lmstudio',
    baseUrl: 'http://localhost:1234',
    protocol: 'openai',
    compatibility: {
      enabled: true,
      toolsApi: true,
      requestMappings: [
        {
          sourcePath: 'tools',
          targetPath: 'tools',
          transform: 'lmstudio-tools'
        },
        {
          sourcePath: 'model',
          targetPath: 'model',
          transform: 'mapping',
          mapping: {
            'gpt-4': 'llama2-7b-chat',
            'gpt-3.5-turbo': 'llama2-7b-chat'
          }
        }
      ]
    },
    config: {
      baseUrl: 'http://localhost:1234',
      auth: {
        type: 'apikey',
        apiKey: '${LM_STUDIO_API_KEY}'
      },
      models: {
        'llama2-7b-chat': {
          maxTokens: 4096,
          temperature: 0.7,
          toolsEnabled: true
        }
      }
    }
  },
  modules: {
    llmSwitch: { type: 'openai-passthrough' },
    workflow: { type: 'streaming-control' },
    compatibility: { type: 'lmstudio-compatibility' },
    provider: { type: 'lmstudio-http' }
  }
};

// ä½¿ç”¨å·¥å…·è°ƒç”¨
const toolCallRequest = {
  messages: [
    { role: 'user', content: 'What is the weather in Beijing?' }
  ],
  tools: [
    {
      type: 'function',
      function: {
        name: 'get_weather',
        description: 'Get weather information for a location',
        parameters: {
          type: 'object',
          properties: {
            location: {
              type: 'string',
              description: 'The city and state, e.g. San Francisco, CA'
            }
          },
          required: ['location']
        }
      }
    }
  ]
};

const response = await pipeline.processRequest(toolCallRequest);
```

### Provideré…ç½®ç¤ºä¾‹

```typescript
const qwenProviderConfig = {
  id: 'qwen-provider',
  type: 'qwen',
  protocol: 'openai',
  compatibility: {
    enabled: true,
    requestMappings: [
      {
        sourcePath: 'model',
        targetPath: 'model',
        transform: 'mapping',
        mapping: {
          'gpt-4': 'qwen3-coder-plus',
          'gpt-3.5-turbo': 'qwen3-coder'
        }
      }
    ],
    responseMappings: [
      {
        sourcePath: 'usage.prompt_tokens',
        targetPath: 'usage.prompt_tokens',
        transform: 'direct'
      }
    ]
  },
  config: {
    baseUrl: 'https://portal.qwen.ai/v1',
    auth: {
      type: 'apikey',
      apiKey: '${QWEN_API_KEY}'
    }
  }
};
```

## é…ç½®é€‰é¡¹

### æµæ°´çº¿é…ç½®

```typescript
interface PipelineConfig {
  id: string;                              // æµæ°´çº¿ID (provider.model)
  provider: ProviderConfig;                // Provideré…ç½®
  modules: {
    llmSwitch: {
      type: 'openai-passthrough';          // LLMSwitchç±»å‹
      config?: any;                        // é¢å¤–é…ç½®
    };
    workflow: {
      type: 'streaming-control';           // Workflowç±»å‹
      config: {
        streamingToNonStreaming: boolean;  // æµå¼è½¬éæµå¼
        nonStreamingToStreaming: boolean;  // éæµå¼è½¬æµå¼
      };
    };
    compatibility: {
      type: 'field-mapping';              // Compatibilityç±»å‹
    };
    provider: {
      type: string;                        // Providerç±»å‹
      config: any;                         // Provideré…ç½®
    };
  };
}
```

### è½¬æ¢è§„åˆ™é…ç½®

```typescript
interface TransformationRule {
  sourcePath: string;          // æºJSONè·¯å¾„
  targetPath: string;          // ç›®æ ‡JSONè·¯å¾„
  transform: TransformType;   // è½¬æ¢ç±»å‹
  mapping?: Record<string, any>; // å€¼æ˜ å°„è¡¨
  defaultValue?: any;          // é»˜è®¤å€¼
  required?: boolean;          // æ˜¯å¦å¿…éœ€
}

type TransformType =
  | 'direct'                    // ç›´æ¥æ˜ å°„
  | 'mapping'                   // å€¼æ˜ å°„
  | 'rename'                    // é‡å‘½åå­—æ®µ
  | 'structure'                 // ç»“æ„è½¬æ¢
  | 'array-transform'           // æ•°ç»„è½¬æ¢
  | 'object-transform'          // å¯¹è±¡è½¬æ¢
  | 'conditional'               // æ¡ä»¶è½¬æ¢
  | 'function'                  // è‡ªå®šä¹‰å‡½æ•°
  | 'lmstudio-tools'            // LM Studioå·¥å…·è°ƒç”¨è½¬æ¢
  | 'lmstudio-response'         // LM Studioå“åº”æ ¼å¼è½¬æ¢
```

## é”™è¯¯å¤„ç†

æµæ°´çº¿æ¨¡å—é›†æˆäº†ErrorHandlingCenterï¼Œæä¾›ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š

```typescript
// é”™è¯¯å¤„ç†ç¤ºä¾‹
try {
  const response = await pipeline.processRequest(request);
} catch (error) {
  // é”™è¯¯å·²è‡ªåŠ¨ä¸ŠæŠ¥åˆ°ErrorHandlingCenter
  // åŒ…å«å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
  // - æµæ°´çº¿ID
  // - å¤±è´¥æ¨¡å—
  // - è¯·æ±‚ID
  // - æ—¶é—´æˆ³
  // - é”™è¯¯å †æ ˆ
}
```

### è®¤è¯é”™è¯¯å¤„ç†

- **APIKeyå¤±æ•ˆ**: ç›´æ¥è¿”å›é”™è¯¯
- **OAuthè¿‡æœŸ**: è‡ªåŠ¨åˆ·æ–°Token
- **è®¤è¯å¤±è´¥**: è§¦å‘æµè§ˆå™¨é‡æ–°è®¤è¯

## è°ƒè¯•æ”¯æŒ

æ¯ä¸ªè¯·æ±‚å’Œå“åº”éƒ½ä¼šè¢«è®°å½•ä¸ºå•ç‹¬çš„debugä¿¡æ¯ï¼š

```typescript
// Debugæ—¥å¿—åŒ…å«æ¯ä¸ªå¤„ç†é˜¶æ®µçš„ä¿¡æ¯
{
  pipeline: 'qwen.qwen3-coder-plus',
  stage: 'compatibility.request',
  timestamp: '2025-01-22T10:30:00Z',
  data: { /* è½¬æ¢åçš„è¯·æ±‚æ•°æ® */ },
  metadata: {
    requestId: 'req-123',
    duration: 5,
    transformRules: ['model-mapping', 'max_tokens-direct']
  }
}
```

## æ€§èƒ½è€ƒè™‘

- **é¢„åˆ›å»ºæµæ°´çº¿**: é¿å…è¿è¡Œæ—¶åˆ›å»ºå¼€é”€
- **æ¨¡å—åŒ–è®¾è®¡**: æ”¯æŒæŒ‰éœ€åŠ è½½å’Œæ›¿æ¢
- **å¹¶è¡Œå¤„ç†**: æ”¯æŒå¤šä¸ªè¯·æ±‚å¹¶è¡Œå¤„ç†
- **å†…å­˜ç®¡ç†**: åŠæ—¶æ¸…ç†ä¸­é—´æ•°æ®

## æ‰©å±•æ€§

### æ·»åŠ æ–°çš„LLMSwitchå®ç°

```typescript
class NewLLMSwitch implements LLMSwitchModule {
  async transformRequest(request: any): Promise<any> {
    // å®ç°åè®®è½¬æ¢é€»è¾‘
  }

  async transformResponse(response: any): Promise<any> {
    // å®ç°å“åº”è½¬æ¢é€»è¾‘
  }
}
```

### æ·»åŠ æ–°çš„Providerå®ç°

```typescript
class NewProvider extends BaseProvider {
  async sendRequest(request: any): Promise<any> {
    // å®ç°Providerç‰¹å®šçš„è¯·æ±‚å¤„ç†
  }

  async authenticate(): Promise<AuthResult> {
    // å®ç°è®¤è¯é€»è¾‘
  }
}
```

## ä¾èµ–å…³ç³»

- **rcc-basemodule**: åŸºç¡€æ¨¡å—åŠŸèƒ½
- **errorhandling**: é”™è¯¯å¤„ç†ä¸­å¿ƒ
- **debugcenter**: è°ƒè¯•ä¸­å¿ƒé›†æˆ
- **config-manager**: é…ç½®ç®¡ç†
- **transformation-tables**: è½¬æ¢è¡¨é…ç½®

## ç‰ˆæœ¬ä¿¡æ¯

- **å½“å‰ç‰ˆæœ¬**: 1.0.0
- **å…¼å®¹æ€§**: RouteCodex v0.2+
- **æœ€åæ›´æ–°**: 2025-01-22