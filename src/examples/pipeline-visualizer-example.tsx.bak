/**
 * RouteCodex 流水线可视化系统使用示例
 *
 * 此文件展示了如何使用流水线可视化系统的各种功能
 */

import React, { useState, useEffect } from 'react';
import {
  PipelineDashboard,
  createPipelineData,
  createPipelineNode,
  PipelineData,
  PipelineNode
} from '../components/pipeline-visualizer';

// 创建示例流水线数据
const createExamplePipelineData = (): PipelineData => {
  return createPipelineData({
    id: 'rcc4-demo-pipeline',
    name: 'RCC4 Demo Pipeline',
    overallStatus: 'running',
    nodes: [
      createPipelineNode({
        id: 'llm-switch',
        name: 'LLM Switch',
        type: 'Dynamic Router',
        layer: '1',
        status: 'running',
        description: '动态路由分类模块，负责请求分析和路由选择',
        io: {
          input: {
            model: 'qwen3-4b-thinking-2507-mlx',
            messages: [
              { role: 'user', content: 'Hello, can you help me with a coding task?' }
            ],
            tools: [
              {
                type: 'function',
                function: {
                  name: 'execute_code',
                  description: 'Execute Python code',
                  parameters: {
                    type: 'object',
                    properties: {
                      code: { type: 'string', description: 'Python code to execute' }
                    },
                    required: ['code']
                  }
                }
              }
            ],
            temperature: 0.7,
            max_tokens: 2048
          },
          output: {
            model: 'qwen3-4b-thinking-2507-mlx',
            messages: [
              { role: 'user', content: 'Hello, can you help me with a coding task?' }
            ],
            tools: [
              {
                type: 'function',
                function: {
                  name: 'execute_code',
                  description: 'Execute Python code',
                  parameters: {
                    type: 'object',
                    properties: {
                      code: { type: 'string', description: 'Python code to execute' }
                    },
                    required: ['code']
                  }
                }
              }
            ],
            temperature: 0.7,
            max_tokens: 2048,
            _metadata: {
              switchType: 'openai-passthrough',
              timestamp: Date.now(),
              originalProtocol: 'openai',
              targetProtocol: 'openai',
              routingCategory: 'coding',
              confidence: 0.95
            }
          },
          timestamp: Date.now(),
          processingTime: 156
        },
        config: {
          enabled: true,
          routingRules: [
            { pattern: 'code.*execute', category: 'coding' },
            { pattern: 'search.*find', category: 'websearch' }
          ],
          timeout: 5000
        }
      }),
      createPipelineNode({
        id: 'compatibility',
        name: 'Compatibility',
        type: 'Format Transformer',
        layer: '2',
        status: 'running',
        description: '兼容性转换模块，负责协议格式转换',
        io: {
          input: {
            model: 'qwen3-4b-thinking-2507-mlx',
            messages: [
              { role: 'user', content: 'Hello, can you help me with a coding task?' }
            ],
            tools: [
              {
                type: 'function',
                function: {
                  name: 'execute_code',
                  description: 'Execute Python code',
                  parameters: {
                    type: 'object',
                    properties: {
                      code: { type: 'string', description: 'Python code to execute' }
                    },
                    required: ['code']
                  }
                }
              }
            ],
            temperature: 0.7,
            max_tokens: 2048,
            _metadata: {
              switchType: 'openai-passthrough',
              timestamp: Date.now(),
              originalProtocol: 'openai',
              targetProtocol: 'openai',
              routingCategory: 'coding',
              confidence: 0.95
            }
          },
          output: {
            model: 'qwen3-4b-thinking-2507-mlx',
            messages: [
              { role: 'user', content: 'Hello, can you help me with a coding task?' }
            ],
            tools: [
              {
                type: 'function',
                function: {
                  name: 'execute_code',
                  description: 'Execute Python code',
                  parameters: {
                    type: 'object',
                    properties: {
                      code: { type: 'string', description: 'Python code to execute' }
                    },
                    required: ['code']
                  }
                }
              }
            ],
            temperature: 0.7,
            max_tokens: 2048,
            _metadata: {
              switchType: 'openai-passthrough',
              timestamp: Date.now(),
              originalProtocol: 'openai',
              targetProtocol: 'lmstudio',
              routingCategory: 'coding',
              confidence: 0.95,
              transformed: true
            }
          },
          timestamp: Date.now(),
          processingTime: 89
        },
        config: {
          transformationRules: [
            {
              id: 'openai-to-lmstudio-tools',
              transform: 'mapping',
              sourcePath: 'tools',
              targetPath: 'tools',
              mapping: {
                'type': 'type',
                'function': 'function'
              }
            }
          ],
          enableTools: true
        }
      }),
      createPipelineNode({
        id: 'provider',
        name: 'Provider',
        type: 'HTTP Server',
        layer: '3',
        status: 'running',
        description: 'Provider模块，负责HTTP通信和认证',
        io: {
          input: {
            model: 'qwen3-4b-thinking-2507-mlx',
            messages: [
              { role: 'user', content: 'Hello, can you help me with a coding task?' }
            ],
            tools: [
              {
                type: 'function',
                function: {
                  name: 'execute_code',
                  description: 'Execute Python code',
                  parameters: {
                    type: 'object',
                    properties: {
                      code: { type: 'string', description: 'Python code to execute' }
                    },
                    required: ['code']
                  }
                }
              }
            ],
            temperature: 0.7,
            max_tokens: 2048,
            _metadata: {
              switchType: 'openai-passthrough',
              timestamp: Date.now(),
              originalProtocol: 'openai',
              targetProtocol: 'lmstudio',
              routingCategory: 'coding',
              confidence: 0.95,
              transformed: true
            }
          },
          output: {
            id: 'chat-1234567890',
            object: 'chat.completion',
            created: 1640995200,
            model: 'qwen3-4b-thinking-2507-mlx',
            choices: [
              {
                index: 0,
                message: {
                  role: 'assistant',
                  content: 'I\'d be happy to help you with your coding task! Could you please provide more details about what you\'re trying to accomplish?'
                },
                finish_reason: 'stop'
              }
            ],
            usage: {
              prompt_tokens: 45,
              completion_tokens: 28,
              total_tokens: 73
            }
          },
          timestamp: Date.now(),
          processingTime: 342
        },
        config: {
          type: 'lmstudio',
          baseUrl: 'http://localhost:1234',
          auth: {
            type: 'none'
          },
          timeout: 30000,
          maxRetries: 3
        }
      }),
      createPipelineNode({
        id: 'ai-service',
        name: 'AI Service',
        type: 'External Provider',
        layer: '4',
        status: 'success',
        description: '外部AI服务，负责模型推理和生成',
        io: {
          input: {
            model: 'qwen3-4b-thinking-2507-mlx',
            messages: [
              { role: 'user', content: 'Hello, can you help me with a coding task?' }
            ],
            tools: [
              {
                type: 'function',
                function: {
                  name: 'execute_code',
                  description: 'Execute Python code',
                  parameters: {
                    type: 'object',
                    properties: {
                      code: { type: 'string', description: 'Python code to execute' }
                    },
                    required: ['code']
                  }
                }
              }
            ],
            temperature: 0.7,
            max_tokens: 2048
          },
          output: {
            id: 'chat-1234567890',
            object: 'chat.completion',
            created: 1640995200,
            model: 'qwen3-4b-thinking-2507-mlx',
            choices: [
              {
                index: 0,
                message: {
                  role: 'assistant',
                  content: 'I\'d be happy to help you with your coding task! Could you please provide more details about what you\'re trying to accomplish?'
                },
                finish_reason: 'stop'
              }
            ],
            usage: {
              prompt_tokens: 45,
              completion_tokens: 28,
              total_tokens: 73
            }
          },
          timestamp: Date.now(),
          processingTime: 567
        },
        config: {
          provider: 'LM Studio',
          model: 'qwen3-4b-thinking-2507-mlx',
          endpoint: '/v1/chat/completions',
          capabilities: ['chat', 'function-calling', 'streaming']
        }
      })
    ],
    connections: [
      { sourceId: 'llm-switch', targetId: 'compatibility', status: 'active', type: 'data' },
      { sourceId: 'compatibility', targetId: 'provider', status: 'active', type: 'data' },
      { sourceId: 'provider', targetId: 'ai-service', status: 'active', type: 'data' }
    ],
    metrics: {
      totalRequests: 1250,
      successRate: 0.95,
      averageResponseTime: 350,
      timestamp: Date.now(),
      errorCount: 62,
      concurrentRequests: 12,
      throughput: 45.5
    },
    tags: ['demo', 'rcc4', 'pipeline']
  });
};

// 模拟实时数据更新
const simulateRealTimeUpdate = (data: PipelineData): PipelineData => {
  return {
    ...data,
    nodes: data.nodes.map(node => {
      const random = Math.random();
      let newStatus = node.status;

      if (random < 0.05) {
        newStatus = 'error';
        node.error = '处理超时';
      } else if (random < 0.15) {
        newStatus = 'running';
        node.error = undefined;
      } else if (random < 0.25) {
        newStatus = 'success';
        node.error = undefined;
      }

      return {
        ...node,
        status: newStatus,
        io: {
          ...node.io,
          timestamp: Date.now(),
          processingTime: Math.floor(Math.random() * 1000) + 100
        }
      };
    }),
    connections: data.connections.map(conn => ({
      ...conn,
      status: Math.random() > 0.9 ? 'error' : 'active'
    })),
    metrics: {
      ...data.metrics,
      totalRequests: data.metrics.totalRequests + Math.floor(Math.random() * 5),
      successRate: Math.max(0.85, Math.min(1.0, data.metrics.successRate + (Math.random() - 0.5) * 0.05)),
      averageResponseTime: Math.floor(Math.random() * 200) + 250,
      timestamp: Date.now()
    }
  };
};

// 示例组件
export const PipelineVisualizerExample: React.FC = () => {
  const [pipelineData, setPipelineData] = useState<PipelineData>(createExamplePipelineData());
  const [theme, setTheme] = useState<'light' | 'dark'>('light');
  const [isRealTimeEnabled, setIsRealTimeEnabled] = useState(true);

  // 模拟实时数据更新
  useEffect(() => {
    if (!isRealTimeEnabled) return;

    const interval = setInterval(() => {
      setPipelineData(prev => simulateRealTimeUpdate(prev));
    }, 2000);

    return () => clearInterval(interval);
  }, [isRealTimeEnabled]);

  // 节点点击处理
  const handleNodeClick = (node: PipelineNode) => {
    console.log('Node clicked:', node);
    // 这里可以添加自定义处理逻辑
  };

  // 数据更新处理
  const handleDataUpdate = (data: PipelineData) => {
    console.log('Data updated:', data);
    // 这里可以添加自定义处理逻辑
  };

  // 手动刷新数据
  const handleRefresh = () => {
    setPipelineData(createExamplePipelineData());
  };

  return (
    <div style={{ padding: '20px' }}>
      <h1 style={{ marginBottom: '20px', color: theme === 'dark' ? '#fff' : '#000' }}>
        RouteCodex 流水线可视化系统示例
      </h1>

      {/* 控制面板 */}
      <div style={{ marginBottom: '20px', display: 'flex', gap: '10px', alignItems: 'center' }}>
        <button
          onClick={() => setTheme(theme === 'light' ? 'dark' : 'light')}
          style={{
            padding: '8px 16px',
            border: '1px solid #ccc',
            borderRadius: '4px',
            background: theme === 'light' ? '#fff' : '#333',
            color: theme === 'light' ? '#000' : '#fff',
            cursor: 'pointer'
          }}
        >
          切换主题 ({theme})
        </button>

        <button
          onClick={() => setIsRealTimeEnabled(!isRealTimeEnabled)}
          style={{
            padding: '8px 16px',
            border: '1px solid #ccc',
            borderRadius: '4px',
            background: isRealTimeEnabled ? '#4caf50' : '#f44336',
            color: '#fff',
            cursor: 'pointer'
          }}
        >
          {isRealTimeEnabled ? '停止实时更新' : '启动实时更新'}
        </button>

        <button
          onClick={handleRefresh}
          style={{
            padding: '8px 16px',
            border: '1px solid #ccc',
            borderRadius: '4px',
            background: '#2196f3',
            color: '#fff',
            cursor: 'pointer'
          }}
        >
          刷新数据
        </button>
      </div>

      {/* 流水线可视化 */}
      <PipelineDashboard
        initialData={pipelineData}
        width={1200}
        height={800}
        theme={theme}
        enableRealTime={isRealTimeEnabled}
        updateInterval={2000}
        onNodeClick={handleNodeClick}
        onDataUpdate={handleDataUpdate}
      />
    </div>
  );
};

// 简单使用示例
export const SimpleExample: React.FC = () => {
  const [data] = useState<PipelineData>(createExamplePipelineData());

  return (
    <div style={{ padding: '20px' }}>
      <h2 style={{ marginBottom: '20px' }}>简单使用示例</h2>
      <PipelineDashboard
        initialData={data}
        width={1000}
        height={600}
        theme="light"
        enableRealTime={false}
      />
    </div>
  );
};

// 高级使用示例
export const AdvancedExample: React.FC = () => {
  const [data, setData] = useState<PipelineData>(createExamplePipelineData());

  // 模拟从API获取数据
  const fetchData = async (): Promise<PipelineData> => {
    // 这里可以替换为真实的API调用
    await new Promise(resolve => setTimeout(resolve, 500));
    return createExamplePipelineData();
  };

  return (
    <div style={{ padding: '20px' }}>
      <h2 style={{ marginBottom: '20px' }}>高级使用示例</h2>
      <PipelineDashboard
        initialData={data}
        fetchData={fetchData}
        width={1400}
        height={900}
        theme="dark"
        enableRealTime={true}
        updateInterval={3000}
        onNodeClick={(node) => {
          alert(`点击了节点: ${node.name}`);
        }}
        onDataUpdate={(newData) => {
          setData(newData);
        }}
      />
    </div>
  );
};

export default PipelineVisualizerExample;