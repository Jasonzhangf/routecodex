/**
 * JSONLæ—¥å¿—è§£æå™¨
 * 
 * é«˜æ•ˆè§£æJSON Linesæ ¼å¼çš„æ—¥å¿—æ–‡ä»¶
 */

import { createReadStream } from 'fs';
import { createInterface } from 'readline';
import * as path from 'path';

import type { UnifiedLogEntry } from '../types.js';
import { LogLevel } from '../types.js';

/**
 * JSONLè§£æå™¨é…ç½®
 */
export interface JsonlParserConfig {
  /** æ‰¹å¤„ç†å¤§å° */
  batchSize?: number;
  /** æœ€å¤§è¡Œé•¿åº¦ */
  maxLineLength?: number;
  /** è·³è¿‡å¤§æ–‡ä»¶ */
  skipLargeFiles?: boolean;
  /** å¤§æ–‡ä»¶é˜ˆå€¼ (bytes) */
  largeFileThreshold?: number;
  /** é”™è¯¯å¤„ç†ç­–ç•¥ */
  errorHandling?: 'skip' | 'include' | 'strict';
  /** æ—¶é—´æˆ³éªŒè¯ */
  validateTimestamps?: boolean;
  /** å¹¶è¡Œå¤„ç† */
  parallel?: boolean;
  /** æœ€å¤§å¹¶å‘æ•° */
  maxConcurrency?: number;
}

/**
 * è§£æè¿›åº¦
 */
export interface ParseProgress {
  /** å·²å¤„ç†çš„æ–‡ä»¶æ•° */
  filesProcessed: number;
  /** æ€»æ–‡ä»¶æ•° */
  totalFiles: number;
  /** å·²å¤„ç†çš„æ—¥å¿—æ¡ç›® */
  entriesProcessed: number;
  /** æœ‰æ•ˆçš„æ—¥å¿—æ¡ç›® */
  validEntries: number;
  /** æ— æ•ˆ/é”™è¯¯çš„æ—¥å¿—æ¡ç›® */
  invalidEntries: number;
  /** å½“å‰æ–‡ä»¶è·¯å¾„ */
  currentFile?: string;
  /** å½“å‰æ–‡ä»¶è¿›åº¦ (0-1) */
  currentFileProgress?: number;
}

/**
 * è§£æç»“æœ
 */
export interface ParseResult {
  /** è§£æçš„æ—¥å¿—æ¡ç›® */
  entries: UnifiedLogEntry[];
  /** é”™è¯¯ä¿¡æ¯ */
  errors: ParseError[];
  /** è§£æç»Ÿè®¡ */
  stats: ParseStats;
  /** è§£æè€—æ—¶ */
  parseTime: number;
}

/**
 * è§£æé”™è¯¯
 */
export interface ParseError {
  /** æ–‡ä»¶è·¯å¾„ */
  filePath: string;
  /** è¡Œå· */
  lineNumber: number;
  /** é”™è¯¯ç±»å‹ */
  errorType: 'invalid_json' | 'missing_timestamp' | 'invalid_level' | 'schema_validation' | 'other';
  /** é”™è¯¯æ¶ˆæ¯ */
  message: string;
  /** åŸå§‹å†…å®¹ */
  rawContent?: string;
  /** æ—¶é—´æˆ³ */
  timestamp: number;
}

/**
 * è§£æç»Ÿè®¡
 */
export interface ParseStats {
  /** æ€»æ–‡ä»¶æ•° */
  totalFiles: number;
  /** æˆåŠŸæ–‡ä»¶æ•° */
  successfulFiles: number;
  /** å¤±è´¥æ–‡ä»¶æ•° */
  failedFiles: number;
  /** æ€»è¡Œæ•° */
  totalLines: number;
  /** æœ‰æ•ˆæ¡ç›®æ•° */
  validEntries: number;
  /** æ— æ•ˆæ¡ç›®æ•° */
  invalidEntries: number;
  /** è·³è¿‡çš„æ¡ç›®æ•° */
  skippedEntries: number;
  /** æ—¶é—´èŒƒå›´ */
  timeRange?: {
    start: number;
    end: number;
  };
  /** æ¨¡å—åˆ†å¸ƒ */
  moduleDistribution: Record<string, number>;
  /** çº§åˆ«åˆ†å¸ƒ */
  levelDistribution: Record<LogLevel, number>;
}

/**
 * JSONLæ—¥å¿—è§£æå™¨
 */
export class JsonlLogParser {
  private config: Required<JsonlParserConfig>;

  constructor(config: JsonlParserConfig = {}) {
    this.config = {
      batchSize: config.batchSize || 1000,
      maxLineLength: config.maxLineLength || 10000,
      skipLargeFiles: config.skipLargeFiles ?? false,
      largeFileThreshold: config.largeFileThreshold || 100 * 1024 * 1024, // 100MB
      errorHandling: config.errorHandling || 'skip',
      validateTimestamps: config.validateTimestamps ?? true,
      parallel: config.parallel ?? false,
      maxConcurrency: config.maxConcurrency || 5
    };
  }

  /**
   * è§£ææ—¥å¿—æ–‡ä»¶
   */
  async parseFile(filePath: string): Promise<UnifiedLogEntry[]> {
    const result = await this.parseFiles([filePath]);
    return result.entries;
  }

  /**
   * è§£æå¤šä¸ªæ—¥å¿—æ–‡ä»¶
   */
  async parseFiles(filePaths: string[]): Promise<ParseResult> {
    const startTime = Date.now();
    const allEntries: UnifiedLogEntry[] = [];
    const allErrors: ParseError[] = [];
    let totalStats: ParseStats = this.createEmptyStats();

    console.log(`ğŸ“– å¼€å§‹è§£æ ${filePaths.length} ä¸ªæ—¥å¿—æ–‡ä»¶...`);

    if (this.config.parallel) {
      // å¹¶è¡Œå¤„ç†
      const results = await this.parseFilesParallel(filePaths);
      
      for (const result of results) {
        allEntries.push(...result.entries);
        allErrors.push(...result.errors);
        totalStats = this.mergeStats(totalStats, result.stats);
      }
    } else {
      // ä¸²è¡Œå¤„ç†
      for (let i = 0; i < filePaths.length; i++) {
        const filePath = filePaths[i];
        
        console.log(`  è§£ææ–‡ä»¶ ${i + 1}/${filePaths.length}: ${path.basename(filePath)}`);
        
        try {
          const result = await this.parseSingleFile(filePath);
          allEntries.push(...result.entries);
          allErrors.push(...result.errors);
          totalStats = this.mergeStats(totalStats, result.stats);
        } catch (error) {
          console.error(`è§£ææ–‡ä»¶å¤±è´¥ ${filePath}:`, error);
          totalStats.failedFiles++;
        }
      }
    }

    // æ’åºï¼ˆæŒ‰æ—¶é—´æˆ³ï¼‰
    allEntries.sort((a, b) => a.timestamp - b.timestamp);

    const parseTime = Date.now() - startTime;
    
    console.log(`âœ… è§£æå®Œæˆï¼Œå¤„ç† ${allEntries.length} æ¡æ—¥å¿—ï¼Œè€—æ—¶: ${parseTime}ms`);
    console.log(`   æœ‰æ•ˆæ¡ç›®: ${totalStats.validEntries}, æ— æ•ˆæ¡ç›®: ${totalStats.invalidEntries}`);

    return {
      entries: allEntries,
      errors: allErrors,
      stats: totalStats,
      parseTime
    };
  }

  /**
   * è§£ææ—¥å¿—å†…å®¹
   */
  async parseContent(content: string): Promise<UnifiedLogEntry[]> {
    const lines = content.split('\n').filter(line => line.trim());
    const entries: UnifiedLogEntry[] = [];
    
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i];
      const entry = this.parseLine(line, 'content', i + 1);
      
      if (entry) {
        entries.push(entry);
      }
    }
    
    return entries;
  }

  /**
   * éªŒè¯æ—¥å¿—æ ¼å¼
   */
  validate(entry: any): entry is UnifiedLogEntry {
    if (!entry || typeof entry !== 'object') {
      return false;
    }
    
    // æ£€æŸ¥å¿…éœ€å­—æ®µ
    if (!entry.timestamp || !entry.level || !entry.moduleId || !entry.moduleType) {
      return false;
    }
    
    // æ£€æŸ¥æ—¥å¿—çº§åˆ«
    if (!Object.values(LogLevel).includes(entry.level)) {
      return false;
    }
    
    // æ£€æŸ¥æ—¶é—´æˆ³
    if (this.config.validateTimestamps) {
      if (typeof entry.timestamp !== 'number' || entry.timestamp <= 0) {
        return false;
      }
      
      // æ—¶é—´æˆ³åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆè¿‡å»1å¹´åˆ°æœªæ¥1å°æ—¶ï¼‰
      const now = Date.now();
      const oneYearAgo = now - 365 * 24 * 60 * 60 * 1000;
      const oneHourLater = now + 60 * 60 * 1000;
      
      if (entry.timestamp < oneYearAgo || entry.timestamp > oneHourLater) {
        return false;
      }
    }
    
    return true;
  }

  /**
   * è§£æå•ä¸ªæ–‡ä»¶
   */
  private async parseSingleFile(filePath: string): Promise<ParseResult> {
    const startTime = Date.now();
    const entries: UnifiedLogEntry[] = [];
    const errors: ParseError[] = [];
    const stats = this.createEmptyStats();
    
    stats.totalFiles++;
    
    try {
      // æ£€æŸ¥æ–‡ä»¶å¤§å°
      const fileStats = await this.getFileStats(filePath);
      if (!fileStats) {
        throw new Error('æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯');
      }
      
      if (this.config.skipLargeFiles && fileStats.size > this.config.largeFileThreshold) {
        console.warn(`è·³è¿‡æ–‡ä»¶: ${filePath} (å¤§å°: ${fileStats.size} bytes)`);
        stats.skippedEntries += Math.floor(fileStats.size / 200); // ä¼°ç®—
        return { entries, errors, stats, parseTime: Date.now() - startTime };
      }
      
      // è¯»å–å¹¶è§£ææ–‡ä»¶
      await this.parseFileStream(filePath, entries, errors, stats);
      
      stats.successfulFiles++;
      
    } catch (error) {
      console.error(`è§£ææ–‡ä»¶å¤±è´¥ ${filePath}:`, error);
      stats.failedFiles++;
      errors.push({
        filePath,
        lineNumber: 0,
        errorType: 'other',
        message: error instanceof Error ? error.message : String(error),
        timestamp: Date.now()
      });
    }
    
    const parseTime = Date.now() - startTime;
    return { entries, errors, stats, parseTime };
  }

  /**
   * è§£ææ–‡ä»¶æµ
   */
  private async parseFileStream(
    filePath: string,
    entries: UnifiedLogEntry[],
    errors: ParseError[],
    stats: ParseStats
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      const fileStream = createReadStream(filePath, { encoding: 'utf8' });
      const rl = createInterface({
        input: fileStream,
        crlfDelay: Infinity
      });

      let lineNumber = 0;
      let batch: string[] = [];

      rl.on('line', (line) => {
        lineNumber++;
        stats.totalLines++;

        // è·³è¿‡ç©ºè¡Œ
        if (!line.trim()) {
          return;
        }

        // æ£€æŸ¥è¡Œé•¿åº¦
        if (line.length > this.config.maxLineLength) {
          if (this.config.errorHandling === 'skip') {
            stats.invalidEntries++;
            return;
          } else if (this.config.errorHandling === 'strict') {
            errors.push({
              filePath,
              lineNumber,
              errorType: 'other',
              message: `Line too long: ${line.length} > ${this.config.maxLineLength}`,
              rawContent: line.substring(0, 100),
              timestamp: Date.now()
            });
            return;
          }
        }

        batch.push(line);

        // æ‰¹é‡å¤„ç†
        if (batch.length >= this.config.batchSize) {
          this.processBatch(batch, filePath, lineNumber - batch.length + 1, entries, errors, stats);
          batch = [];
        }
      });

      rl.on('close', () => {
        // å¤„ç†å‰©ä½™çš„æ‰¹æ¬¡
        if (batch.length > 0) {
          this.processBatch(batch, filePath, lineNumber - batch.length + 1, entries, errors, stats);
        }
        resolve();
      });

      rl.on('error', (error) => {
        reject(error);
      });
    });
  }

  /**
   * å¤„ç†æ‰¹æ¬¡
   */
  private processBatch(
    lines: string[],
    filePath: string,
    startLineNumber: number,
    entries: UnifiedLogEntry[],
    errors: ParseError[],
    stats: ParseStats
  ): void {
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i];
      const lineNumber = startLineNumber + i;
      
      const entry = this.parseLine(line, filePath, lineNumber);
      
      if (entry) {
        entries.push(entry);
        stats.validEntries++;
        
        // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        this.updateStats(entry, stats);
      } else {
        stats.invalidEntries++;
      }
    }
  }

  /**
   * è§£æå•è¡Œ
   */
  private parseLine(line: string, filePath: string, lineNumber: number): UnifiedLogEntry | null {
    try {
      const parsed = JSON.parse(line);
      
      if (!this.validate(parsed)) {
        this.handleValidationError(line, filePath, lineNumber, 'schema_validation');
        return null;
      }
      
      return parsed as UnifiedLogEntry;
      
    } catch (error) {
      // JSONè§£æé”™è¯¯
      if (error instanceof SyntaxError) {
        this.handleValidationError(line, filePath, lineNumber, 'invalid_json', error.message);
      } else {
        this.handleValidationError(line, filePath, lineNumber, 'other', String(error));
      }
      return null;
    }
  }

  /**
   * å¤„ç†éªŒè¯é”™è¯¯
   */
  private handleValidationError(
    line: string,
    filePath: string,
    lineNumber: number,
    errorType: ParseError['errorType'],
    message?: string
  ): void {
    const error: ParseError = {
      filePath,
      lineNumber,
      errorType,
      message: message || `Validation failed for ${errorType}`,
      rawContent: line.substring(0, 200),
      timestamp: Date.now()
    };

    if (this.config.errorHandling === 'strict') {
      throw new Error(`Parse error at ${filePath}:${lineNumber} - ${error.message}`);
    } else if (this.config.errorHandling === 'include') {
      // åœ¨ä¸¥æ ¼æ¨¡å¼ä¸‹ä¼šæŠ›å‡ºé”™è¯¯ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
      console.warn(`è§£æé”™è¯¯: ${filePath}:${lineNumber} - ${error.message}`);
    }
  }

  /**
   * æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
   */
  private updateStats(entry: UnifiedLogEntry, stats: ParseStats): void {
    // æ¨¡å—åˆ†å¸ƒ
    if (!stats.moduleDistribution[entry.moduleId]) {
      stats.moduleDistribution[entry.moduleId] = 0;
    }
    stats.moduleDistribution[entry.moduleId]++;
    
    // çº§åˆ«åˆ†å¸ƒ
    stats.levelDistribution[entry.level]++;
    
    // æ—¶é—´èŒƒå›´
    if (!stats.timeRange) {
      stats.timeRange = {
        start: entry.timestamp,
        end: entry.timestamp
      };
    } else {
      stats.timeRange.start = Math.min(stats.timeRange.start, entry.timestamp);
      stats.timeRange.end = Math.max(stats.timeRange.end, entry.timestamp);
    }
  }

  /**
   * å¹¶è¡Œè§£æå¤šä¸ªæ–‡ä»¶
   */
  private async parseFilesParallel(filePaths: string[]): Promise<ParseResult[]> {
    const chunks = this.chunkArray(filePaths, this.config.maxConcurrency);
    const results: ParseResult[] = [];
    
    for (const chunk of chunks) {
      const chunkPromises = chunk.map(filePath => this.parseSingleFile(filePath));
      const chunkResults = await Promise.all(chunkPromises);
      results.push(...chunkResults);
    }
    
    return results;
  }

  /**
   * åˆ†å—æ•°ç»„
   */
  private chunkArray<T>(array: T[], chunkSize: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += chunkSize) {
      chunks.push(array.slice(i, i + chunkSize));
    }
    return chunks;
  }

  /**
   * åˆ›å»ºç©ºçš„ç»Ÿè®¡ä¿¡æ¯
   */
  private createEmptyStats(): ParseStats {
    return {
      totalFiles: 0,
      successfulFiles: 0,
      failedFiles: 0,
      totalLines: 0,
      validEntries: 0,
      invalidEntries: 0,
      skippedEntries: 0,
      moduleDistribution: {},
      levelDistribution: {
        [LogLevel.DEBUG]: 0,
        [LogLevel.INFO]: 0,
        [LogLevel.WARN]: 0,
        [LogLevel.ERROR]: 0
      }
    };
  }

  /**
   * åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
   */
  private mergeStats(stats1: ParseStats, stats2: ParseStats): ParseStats {
    const merged: ParseStats = {
      totalFiles: stats1.totalFiles + stats2.totalFiles,
      successfulFiles: stats1.successfulFiles + stats2.successfulFiles,
      failedFiles: stats1.failedFiles + stats2.failedFiles,
      totalLines: stats1.totalLines + stats2.totalLines,
      validEntries: stats1.validEntries + stats2.validEntries,
      invalidEntries: stats1.invalidEntries + stats2.invalidEntries,
      skippedEntries: stats1.skippedEntries + stats2.skippedEntries,
      moduleDistribution: { ...stats1.moduleDistribution },
      levelDistribution: {
        [LogLevel.DEBUG]: stats1.levelDistribution[LogLevel.DEBUG] + stats2.levelDistribution[LogLevel.DEBUG],
        [LogLevel.INFO]: stats1.levelDistribution[LogLevel.INFO] + stats2.levelDistribution[LogLevel.INFO],
        [LogLevel.WARN]: stats1.levelDistribution[LogLevel.WARN] + stats2.levelDistribution[LogLevel.WARN],
        [LogLevel.ERROR]: stats1.levelDistribution[LogLevel.ERROR] + stats2.levelDistribution[LogLevel.ERROR]
      }
    };

    // åˆå¹¶æ¨¡å—åˆ†å¸ƒ
    for (const [moduleId, count] of Object.entries(stats2.moduleDistribution)) {
      merged.moduleDistribution[moduleId] = (merged.moduleDistribution[moduleId] || 0) + count;
    }

    // åˆå¹¶æ—¶é—´èŒƒå›´
    if (stats1.timeRange && stats2.timeRange) {
      merged.timeRange = {
        start: Math.min(stats1.timeRange.start, stats2.timeRange.start),
        end: Math.max(stats1.timeRange.end, stats2.timeRange.end)
      };
    } else if (stats1.timeRange) {
      merged.timeRange = stats1.timeRange;
    } else if (stats2.timeRange) {
      merged.timeRange = stats2.timeRange;
    }

    return merged;
  }

  /**
   * è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
   */
  private async getFileStats(filePath: string): Promise<{
    size: number;
    isFile: boolean;
  } | null> {
    try {
      const fs = await import('fs');
      const stats = await fs.promises.stat(filePath);
      return {
        size: stats.size,
        isFile: stats.isFile()
      };
    } catch (error) {
      return null;
    }
  }
}

/**
 * ä¾¿æ·çš„è§£æå‡½æ•°
 */
export async function parseLogFiles(
  filePaths: string[],
  config?: JsonlParserConfig
): Promise<ParseResult> {
  const parser = new JsonlLogParser(config);
  return parser.parseFiles(filePaths);
}

/**
 * è§£æå•ä¸ªæ—¥å¿—æ–‡ä»¶
 */
export async function parseLogFile(
  filePath: string,
  config?: JsonlParserConfig
): Promise<UnifiedLogEntry[]> {
  const parser = new JsonlLogParser(config);
  return parser.parseFile(filePath);
}