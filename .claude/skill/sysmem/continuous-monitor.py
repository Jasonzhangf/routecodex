#!/usr/bin/env python3
"""
RouteCodex æŒç»­ç›‘æ§å’Œå®šæœŸæ¸…ç†å·¥å…·
è‡ªåŠ¨åŒ–ç›‘æ§ä»£ç è´¨é‡ï¼Œå®šæœŸæ£€æµ‹æ­»å‡½æ•°å¹¶ç”Ÿæˆæ¸…ç†å»ºè®®
"""

import os
import sys
import json
import subprocess
import datetime
from pathlib import Path
from typing import Dict, List, Optional
import logging

class ContinuousMonitor:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.monitor_dir = self.project_root / ".claude" / "skill" / "sysmem" / "monitor"
        self.monitor_dir.mkdir(parents=True, exist_ok=True)

        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.monitor_dir / "monitor.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

        # ç›‘æ§é…ç½®
        self.config = {
            "max_dead_functions_threshold": 50,
            "max_dead_code_blocks_threshold": 200,
            "cleanup_interval_days": 30,
            "alert_on_new_dead_functions": True
        }

    def load_baseline(self) -> Optional[Dict]:
        """åŠ è½½åŸºçº¿æ•°æ®"""
        baseline_file = self.monitor_dir / "baseline.json"
        if baseline_file.exists():
            with open(baseline_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None

    def save_baseline(self, data: Dict):
        """ä¿å­˜åŸºçº¿æ•°æ®"""
        baseline_file = self.monitor_dir / "baseline.json"
        with open(baseline_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        self.logger.info(f"åŸºçº¿æ•°æ®å·²ä¿å­˜: {baseline_file}")

    def run_analysis(self) -> Dict:
        """è¿è¡Œæ­»å‡½æ•°åˆ†æ"""
        self.logger.info("å¼€å§‹è¿è¡Œæ­»å‡½æ•°åˆ†æ...")

        analyzer_script = self.project_root / ".claude" / "skill" / "sysmem" / "dead_function_analyzer.py"

        try:
            result = subprocess.run(
                [sys.executable, str(analyzer_script), str(self.project_root)],
                capture_output=True,
                text=True,
                check=True
            )

            # è¯»å–åˆ†æç»“æœ
            analysis_file = self.project_root / ".claude" / "skill" / "sysmem" / "dead_function_analysis.json"
            if analysis_file.exists():
                with open(analysis_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                raise Exception("åˆ†æç»“æœæ–‡ä»¶æœªç”Ÿæˆ")

        except subprocess.CalledProcessError as e:
            self.logger.error(f"åˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            self.logger.error(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            raise

    def compare_with_baseline(self, current: Dict, baseline: Optional[Dict]) -> Dict:
        """ä¸åŸºçº¿æ•°æ®æ¯”è¾ƒ"""
        comparison = {
            "timestamp": datetime.datetime.now().isoformat(),
            "baseline_timestamp": baseline.get("analysis_timestamp") if baseline else None,
            "changes": {}
        }

        if not baseline:
            comparison["changes"]["new_analysis"] = True
            return comparison

        current_summary = current.get("cleanup_plan", {}).get("summary", {})
        baseline_summary = baseline.get("cleanup_plan", {}).get("summary", {})

        # æ¯”è¾ƒæœªä½¿ç”¨å‡½æ•°æ•°é‡
        current_unused = current_summary.get("total_unused_functions", 0)
        baseline_unused = baseline_summary.get("total_unused_functions", 0)
        comparison["changes"]["unused_functions"] = {
            "current": current_unused,
            "baseline": baseline_unused,
            "difference": current_unused - baseline_unused
        }

        # æ¯”è¾ƒæ­»ä»£ç å—æ•°é‡
        current_dead_blocks = current_summary.get("dead_code_blocks", 0)
        baseline_dead_blocks = baseline_summary.get("dead_code_blocks", 0)
        comparison["changes"]["dead_code_blocks"] = {
            "current": current_dead_blocks,
            "baseline": baseline_dead_blocks,
            "difference": current_dead_blocks - baseline_dead_blocks
        }

        # æ¯”è¾ƒé£é™©åˆ†å¸ƒ
        current_risks = {
            "high": current_summary.get("high_risk", 0),
            "medium": current_summary.get("medium_risk", 0),
            "low": current_summary.get("low_risk", 0)
        }
        baseline_risks = {
            "high": baseline_summary.get("high_risk", 0),
            "medium": baseline_summary.get("medium_risk", 0),
            "low": baseline_summary.get("low_risk", 0)
        }

        comparison["changes"]["risk_distribution"] = {
            "current": current_risks,
            "baseline": baseline_risks,
            "differences": {
                "high": current_risks["high"] - baseline_risks["high"],
                "medium": current_risks["medium"] - baseline_risks["medium"],
                "low": current_risks["low"] - baseline_risks["low"]
            }
        }

        return comparison

    def check_thresholds(self, current: Dict) -> List[str]:
        """æ£€æŸ¥é˜ˆå€¼å¹¶ç”Ÿæˆè­¦å‘Š"""
        warnings = []
        summary = current.get("cleanup_plan", {}).get("summary", {})

        unused_functions = summary.get("total_unused_functions", 0)
        dead_code_blocks = summary.get("dead_code_blocks", 0)

        if unused_functions > self.config["max_dead_functions_threshold"]:
            warnings.append(
                f"æœªä½¿ç”¨å‡½æ•°æ•°é‡ ({unused_functions}) è¶…è¿‡é˜ˆå€¼ ({self.config['max_dead_functions_threshold']})"
            )

        if dead_code_blocks > self.config["max_dead_code_blocks_threshold"]:
            warnings.append(
                f"æ­»ä»£ç å—æ•°é‡ ({dead_code_blocks}) è¶…è¿‡é˜ˆå€¼ ({self.config['max_dead_code_blocks_threshold']})"
            )

        return warnings

    def generate_alert(self, comparison: Dict, warnings: List[str]) -> Optional[str]:
        """ç”Ÿæˆè­¦æŠ¥æ¶ˆæ¯"""
        if not warnings and not self.config["alert_on_new_dead_functions"]:
            return None

        changes = comparison.get("changes", {})

        alert_parts = ["ğŸš¨ RouteCodex ä»£ç è´¨é‡è­¦æŠ¥"]
        alert_parts.append(f"æ—¶é—´: {comparison['timestamp']}")

        # æ·»åŠ å˜åŒ–ä¿¡æ¯
        if "unused_functions" in changes:
            func_change = changes["unused_functions"]
            if func_change["difference"] > 0:
                alert_parts.append(f"æ–°å¢ {func_change['difference']} ä¸ªæœªä½¿ç”¨å‡½æ•°")

        if "dead_code_blocks" in changes:
            block_change = changes["dead_code_blocks"]
            if block_change["difference"] > 0:
                alert_parts.append(f"æ–°å¢ {block_change['difference']} ä¸ªæ­»ä»£ç å—")

        # æ·»åŠ è­¦å‘Šä¿¡æ¯
        if warnings:
            alert_parts.append("\nâš ï¸ è­¦å‘Š:")
            alert_parts.extend(f"  - {warning}" for warning in warnings)

        # æ·»åŠ å»ºè®®
        alert_parts.append("\nğŸ’¡ å»ºè®®:")
        alert_parts.append("  - è¿è¡Œæ¸…ç†è„šæœ¬: .claude/skill/sysmem/cleanup-scripts/safe-cleanup.sh")
        alert_parts.append("  - æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: .claude/skill/sysmem/ROUTECODEX_DEAD_FUNCTION_CLEANUP_REPORT.md")

        return "\n".join(alert_parts)

    def save_monitoring_result(self, result: Dict):
        """ä¿å­˜ç›‘æ§ç»“æœ"""
        result_file = self.monitor_dir / f"monitoring_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        self.logger.info(f"ç›‘æ§ç»“æœå·²ä¿å­˜: {result_file}")

        # ä¿ç•™æœ€è¿‘30å¤©çš„ç»“æœ
        self._cleanup_old_results()

    def _cleanup_old_results(self):
        """æ¸…ç†æ—§çš„ç›‘æ§ç»“æœ"""
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=30)

        for result_file in self.monitor_dir.glob("monitoring_*.json"):
            try:
                file_date = datetime.datetime.strptime(
                    result_file.stem.split("_")[1],
                    "%Y%m%d_%H%M%S"
                )
                if file_date < cutoff_date:
                    result_file.unlink()
                    self.logger.info(f"åˆ é™¤æ—§çš„ç›‘æ§ç»“æœ: {result_file}")
            except (ValueError, IndexError):
                continue

    def should_run_cleanup(self, baseline: Optional[Dict]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿è¡Œæ¸…ç†"""
        if not baseline:
            return True

        try:
            baseline_time = datetime.datetime.fromisoformat(
                baseline.get("analysis_timestamp", "")
            )
            days_since_baseline = (datetime.datetime.now() - baseline_time).days

            return days_since_baseline >= self.config["cleanup_interval_days"]
        except (ValueError, TypeError):
            return True

    def run_monitoring(self) -> Dict:
        """è¿è¡Œå®Œæ•´çš„ç›‘æ§æµç¨‹"""
        self.logger.info("å¼€å§‹æŒç»­ç›‘æ§...")

        # åŠ è½½åŸºçº¿æ•°æ®
        baseline = self.load_baseline()

        # è¿è¡Œåˆ†æ
        current_analysis = self.run_analysis()

        # æ¯”è¾ƒåˆ†æç»“æœ
        comparison = self.compare_with_baseline(current_analysis, baseline)

        # æ£€æŸ¥é˜ˆå€¼
        warnings = self.check_thresholds(current_analysis)

        # ç”Ÿæˆè­¦æŠ¥
        alert = self.generate_alert(comparison, warnings)

        # æ„å»ºç›‘æ§ç»“æœ
        monitoring_result = {
            "timestamp": datetime.datetime.now().isoformat(),
            "current_analysis": current_analysis,
            "comparison": comparison,
            "warnings": warnings,
            "alert": alert,
            "should_cleanup": self.should_run_cleanup(baseline)
        }

        # ä¿å­˜ç»“æœ
        self.save_monitoring_result(monitoring_result)

        # è¾“å‡ºç»“æœ
        if alert:
            print(alert)
            self.logger.warning("ç”Ÿæˆäº†ä»£ç è´¨é‡è­¦æŠ¥")
        else:
            print("âœ… ä»£ç è´¨é‡ç›‘æ§æ­£å¸¸ï¼Œæ— éœ€è­¦æŠ¥")

        if monitoring_result["should_cleanup"]:
            print("ğŸ’¡ å»ºè®®è¿è¡Œæ¸…ç†æ“ä½œ")

        # æ›´æ–°åŸºçº¿
        self.save_baseline(current_analysis)

        return monitoring_result

    def setup_cron_job(self) -> bool:
        """è®¾ç½®å®šæœŸä»»åŠ¡ï¼ˆä»…é™Unixç³»ç»Ÿï¼‰"""
        if os.name != 'posix':
            self.logger.warning("å®šæœŸä»»åŠ¡è®¾ç½®ä»…æ”¯æŒUnixç³»ç»Ÿ")
            return False

        try:
            # è·å–å½“å‰è„šæœ¬è·¯å¾„
            script_path = Path(__file__).absolute()

            # ç”Ÿæˆcronä»»åŠ¡
            cron_command = f"0 2 * * 0 cd {self.project_root} && {sys.executable} {script_path} monitor >> {self.monitor_dir / 'cron.log'} 2>&1"

            self.logger.info("è¯·æ‰‹åŠ¨æ·»åŠ ä»¥ä¸‹cronä»»åŠ¡:")
            self.logger.info(cron_command)
            self.logger.info("æˆ–è€…è¿è¡Œ: crontab -e ç„¶åæ·»åŠ ä¸Šè¿°è¡Œ")

            return True
        except Exception as e:
            self.logger.error(f"è®¾ç½®å®šæœŸä»»åŠ¡å¤±è´¥: {e}")
            return False

def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python continuous-monitor.py <æ“ä½œ>")
        print("æ“ä½œé€‰é¡¹:")
        print("  monitor   - è¿è¡Œä¸€æ¬¡ç›‘æ§")
        print("  setup-cron - è®¾ç½®å®šæœŸä»»åŠ¡")
        sys.exit(1)

    project_root = "/Users/fanzhang/Documents/github/routecodex-worktree/dev"
    monitor = ContinuousMonitor(project_root)

    operation = sys.argv[1]

    if operation == "monitor":
        try:
            result = monitor.run_monitoring()
            print(f"\nç›‘æ§å®Œæˆï¼Œè¯¦ç»†ç»“æœä¿å­˜åœ¨: {monitor.monitor_dir}")
        except Exception as e:
            print(f"ç›‘æ§å¤±è´¥: {e}")
            sys.exit(1)

    elif operation == "setup-cron":
        if monitor.setup_cron_job():
            print("å®šæœŸä»»åŠ¡è®¾ç½®è¯´æ˜å·²æ˜¾ç¤º")
        else:
            print("å®šæœŸä»»åŠ¡è®¾ç½®å¤±è´¥")
            sys.exit(1)

    else:
        print(f"æœªçŸ¥æ“ä½œ: {operation}")
        sys.exit(1)

if __name__ == "__main__":
    main()