# Providerç»Ÿä¸€é‡æ„æœ€ç»ˆè®¾è®¡æ–¹æ¡ˆ

## ğŸ¯ è®¾è®¡åŸåˆ™

1. **ä¿æŒæ—§ä»£ç ä¸å˜** - legacyä»£ç è·¯å¾„å®Œå…¨ä¸ä¿®æ”¹
2. **æ–°å¢v2è·¯å¾„** - æ–°ä»£ç æ”¾åœ¨ç‹¬ç«‹ç›®å½•
3. **æ¥å£é€æ˜** - æ–°æ—§ç‰ˆæœ¬å¯¹å¤–æ¥å£å®Œå…¨ä¸€è‡´
4. **é…ç½®é©±åŠ¨** - OpenAIå…¼å®¹æœåŠ¡é€šè¿‡é…ç½®åŒºåˆ†
5. **è®¤è¯åˆ†ç¦»** - API Keyå’ŒOAuthç‹¬ç«‹æ¨¡å—

## ğŸ—ï¸ æœ€ç»ˆé¡¹ç›®ç»“æ„

```
src/modules/pipeline/modules/provider/
â”œâ”€â”€ (ç°æœ‰æ–‡ä»¶ä¿æŒä¸å˜)
â”œâ”€â”€ glm-http-provider.ts              # æ—§GLM Provider (ä¸å˜)
â”œâ”€â”€ qwen-provider.ts                  # æ—§Qwen Provider (ä¸å˜)
â”œâ”€â”€ lmstudio-provider-simple.ts       # æ—§LM Studio Provider (ä¸å˜)
â”œâ”€â”€ openai-provider.ts                # æ—§OpenAI Provider (ä¸å˜)
â”œâ”€â”€ iflow-provider.ts                 # æ—§iFlow Provider (ä¸å˜)
â”œâ”€â”€ generic-http-provider.ts          # æ—§Generic Provider (ä¸å˜)
â”œâ”€â”€ generic-responses.ts              # æ—§Generic Responses (ä¸å˜)
â”œâ”€â”€ qwen-oauth.ts                     # æ—§Qwen OAuth (ä¸å˜)
â”œâ”€â”€ iflow-oauth.ts                    # æ—§iFlow OAuth (ä¸å˜)
â”œâ”€â”€ shared/                           # æ—§å…±äº«ä»£ç  (ä¸å˜)
â”‚   â”œâ”€â”€ base-http-provider.ts
â”‚   â””â”€â”€ provider-helpers.ts
â”œâ”€â”€ README.md                         # æ—§README (ä¸å˜)
â”‚
â”œâ”€â”€ v2/                              # æ–°å¢v2ç›®å½• (å…¨æ–°ä»£ç )
â”‚   â”œâ”€â”€ core/                         # æ ¸å¿ƒå®ç°
â”‚   â”‚   â”œâ”€â”€ openai-standard.ts         # OpenAIæ ‡å‡†å®ç°
â”‚   â”‚   â”œâ”€â”€ provider-interface.ts     # ç»Ÿä¸€æ¥å£å®šä¹‰
â”‚   â”‚   â””â”€â”€ provider-factory.ts       # Providerå·¥å‚
â”‚   â”œâ”€â”€ auth/                         # è®¤è¯æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ auth-interface.ts         # è®¤è¯æ¥å£
â”‚   â”‚   â”œâ”€â”€ apikey-auth.ts            # API Keyè®¤è¯å®ç°
â”‚   â”‚   â””â”€â”€ oauth-auth.ts             # OAuthè®¤è¯å®ç°
â”‚   â”œâ”€â”€ config/                       # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ provider-config.ts        # é…ç½®æ¥å£å®šä¹‰
â”‚   â”‚   â””â”€â”€ service-profiles.ts       # å„æœåŠ¡é…ç½®æ¡£æ¡ˆ
â”‚   â”œâ”€â”€ utils/                        # å·¥å…·ç±»
â”‚   â”‚   â”œâ”€â”€ http-client.ts            # ç»Ÿä¸€HTTPå®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ request-normalizer.ts     # è¯·æ±‚æ ‡å‡†åŒ–
â”‚   â”‚   â””â”€â”€ response-normalizer.ts    # å“åº”æ ‡å‡†åŒ–
â”‚   â””â”€â”€ README-v2.md                  # v2ç‰ˆæœ¬è¯´æ˜
```

## ğŸ”§ ç»Ÿä¸€Provideré…ç½®è®¾è®¡

### æ ¸å¿ƒé…ç½®æ¥å£

```typescript
// v2/config/provider-config.ts
export interface UnifiedProviderConfig {
  type: 'openai-standard';
  config: {
    // æœåŠ¡ç±»å‹æ ‡è¯†
    providerType: 'openai' | 'glm' | 'qwen' | 'iflow' | 'lmstudio';

    // åŸºç¡€é…ç½® (å¯é€‰ï¼Œä¼šä½¿ç”¨é¢„è®¾å€¼)
    baseUrl?: string;
    timeout?: number;
    maxRetries?: number;

    // è®¤è¯é…ç½® (å¿…éœ€)
    auth: ApiKeyAuth | OAuthAuth;

    // æœåŠ¡ç‰¹å®šè¦†ç›–é…ç½® (å¯é€‰)
    overrides?: ServiceOverrides;
  };
}

export interface ApiKeyAuth {
  type: 'apikey';
  apiKey: string;
  headerName?: string;    // é»˜è®¤ 'Authorization'
  prefix?: string;        // é»˜è®¤ 'Bearer '
}

export interface OAuthAuth {
  type: 'oauth';
  clientId: string;
  clientSecret?: string;
  tokenUrl: string;
  deviceCodeUrl?: string;
  scopes?: string[];
  tokenFile?: string;
}

export interface ServiceOverrides {
  baseUrl?: string;
  defaultModel?: string;
  headers?: Record<string, string>;
  endpoint?: string;
}
```

### æœåŠ¡é¢„è®¾é…ç½®

```typescript
// v2/config/service-profiles.ts
export const SERVICE_PROFILES = {
  openai: {
    defaultBaseUrl: 'https://api.openai.com/v1',
    defaultEndpoint: '/chat/completions',
    defaultModel: 'gpt-4',
    requiredAuth: ['apikey'],
    optionalAuth: []
  },

  glm: {
    defaultBaseUrl: 'https://open.bigmodel.cn/api/paas/v4',
    defaultEndpoint: '/chat/completions',
    defaultModel: 'glm-4',
    requiredAuth: ['apikey'],
    optionalAuth: [],
    headers: {
      'Content-Type': 'application/json'
    }
  },

  qwen: {
    defaultBaseUrl: 'https://portal.qwen.ai/v1',
    defaultEndpoint: '/chat/completions',
    defaultModel: 'qwen-plus',
    requiredAuth: ['oauth'],
    optionalAuth: ['apikey'],
    headers: {
      'User-Agent': 'google-api-nodejs-client/9.15.1',
      'X-Goog-Api-Client': 'gl-node/22.17.0',
      'Client-Metadata': 'ideType=IDE_UNSPECIFIED,platform=PLATFORM_UNSPECIFIED,pluginType=GEMINI'
    }
  },

  iflow: {
    defaultBaseUrl: 'https://api.iflow.ai/v1',
    defaultEndpoint: '/v1/chat/completions',
    defaultModel: 'kimi',
    requiredAuth: ['oauth'],
    optionalAuth: []
  },

  lmstudio: {
    defaultBaseUrl: 'http://localhost:1234',
    defaultEndpoint: '/v1/chat/completions',
    defaultModel: 'local-model',
    requiredAuth: ['apikey'],
    optionalAuth: [],
    headers: {
      'Content-Type': 'application/json'
    }
  }
};
```

## ğŸš€ ç»Ÿä¸€Providerå®ç°

### æ ¸å¿ƒProviderç±»

```typescript
// v2/core/openai-standard.ts
export class OpenAIStandard implements IProviderV2 {
  readonly id: string;
  readonly type = 'openai-standard';
  readonly providerType: string;
  readonly config: UnifiedProviderConfig;

  private authProvider: IAuthProvider;
  private httpClient: HttpClient;
  private logger: PipelineDebugLogger;
  private serviceProfile: ServiceProfile;
  private isInitialized = false;

  constructor(config: UnifiedProviderConfig, dependencies: ModuleDependencies) {
    this.id = `unified-provider-${Date.now()}`;
    this.config = config;
    this.providerType = config.config.providerType;
    this.logger = dependencies.logger as PipelineDebugLogger;
    this.serviceProfile = this.getServiceProfile();

    // éªŒè¯é…ç½®
    this.validateConfig();

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    this.httpClient = new HttpClient({
      baseUrl: this.getEffectiveBaseUrl(),
      timeout: config.config.timeout || 60000,
      maxRetries: config.config.maxRetries || 3
    });

    // åˆ›å»ºè®¤è¯æä¾›è€…
    this.authProvider = this.createAuthProvider(config.config.auth);
  }

  async initialize(): Promise<void> {
    await this.authProvider.initialize();
    this.isInitialized = true;
    this.logger.logModule(this.id, 'initialized', {
      providerType: this.providerType,
      baseUrl: this.getEffectiveBaseUrl()
    });
  }

  async processIncoming(request: UnknownObject): Promise<ProviderResponse> {
    if (!this.isInitialized) {
      throw new Error('Provider is not initialized');
    }

    const startTime = Date.now();

    try {
      // æ ‡å‡†åŒ–è¯·æ±‚
      const normalizedRequest = this.normalizeRequest(request);

      // æ„å»ºè¯·æ±‚é…ç½®
      const url = this.buildRequestUrl();
      const headers = this.buildRequestHeaders();
      const payload = JSON.stringify(normalizedRequest);

      this.logger.logProviderRequest(this.id, 'request-start', {
        url,
        providerType: this.providerType,
        model: normalizedRequest.model
      });

      // å‘é€HTTPè¯·æ±‚
      const httpResponse = await this.httpClient.post(url, payload, headers);

      // æ ‡å‡†åŒ–å“åº”
      const providerResponse = this.normalizeResponse(httpResponse, startTime);

      this.logger.logProviderRequest(this.id, 'request-success', {
        status: providerResponse.status,
        responseTime: providerResponse.metadata.processingTime
      });

      return providerResponse;

    } catch (error) {
      const processingTime = Date.now() - startTime;
      this.logger.logModule(this.id, 'request-error', {
        error: error instanceof Error ? error.message : String(error),
        processingTime
      });
      throw error;
    }
  }

  async processOutgoing(response: UnknownObject): Promise<UnknownObject> {
    return response;
  }

  async checkHealth(): Promise<boolean> {
    try {
      const url = `${this.getEffectiveBaseUrl()}/models`;
      const headers = this.buildRequestHeaders();
      const response = await this.httpClient.get(url, headers);
      return response.status === 200 || response.status === 404;
    } catch {
      return false;
    }
  }

  async cleanup(): Promise<void> {
    await this.authProvider.cleanup();
    this.isInitialized = false;
  }

  // ç§æœ‰æ–¹æ³•å®ç°...
  private getServiceProfile(): ServiceProfile {
    const profile = SERVICE_PROFILES[this.providerType];
    if (!profile) {
      throw new Error(`Unsupported provider type: ${this.providerType}`);
    }
    return profile;
  }

  private validateConfig(): void {
    const profile = this.serviceProfile;
    const auth = this.config.config.auth;

    // éªŒè¯è®¤è¯ç±»å‹
    const supportedAuthTypes = [...profile.requiredAuth, ...profile.optionalAuth];
    if (!supportedAuthTypes.includes(auth.type)) {
      throw new Error(
        `Auth type '${auth.type}' not supported for provider '${this.providerType}'. ` +
        `Supported types: ${supportedAuthTypes.join(', ')}`
      );
    }
  }

  private getEffectiveBaseUrl(): string {
    return (
      this.config.config.overrides?.baseUrl ||
      this.config.config.baseUrl ||
      this.serviceProfile.defaultBaseUrl
    );
  }

  private buildRequestUrl(): string {
    const baseUrl = this.getEffectiveBaseUrl();
    const endpoint = (
      this.config.config.overrides?.endpoint ||
      this.serviceProfile.defaultEndpoint
    );
    return `${baseUrl}${endpoint}`;
  }

  private buildRequestHeaders(): Record<string, string> {
    const baseHeaders = {
      'Content-Type': 'application/json',
      'User-Agent': 'RouteCodex/2.0'
    };

    // æœåŠ¡ç‰¹å®šå¤´éƒ¨
    const serviceHeaders = this.serviceProfile.headers || {};

    // é…ç½®è¦†ç›–å¤´éƒ¨
    const overrideHeaders = this.config.config.overrides?.headers || {};

    // è®¤è¯å¤´éƒ¨
    const authHeaders = this.authProvider.buildHeaders();

    return {
      ...baseHeaders,
      ...serviceHeaders,
      ...overrideHeaders,
      ...authHeaders
    };
  }

  private normalizeRequest(request: UnknownObject): UnknownObject {
    const normalized = {
      // è®¾ç½®é»˜è®¤æ¨¡å‹
      model: request.model ||
             this.config.config.overrides?.defaultModel ||
             this.serviceProfile.defaultModel,

      // å¤åˆ¶å…¶ä»–å­—æ®µ
      ...request
    };

    // æœåŠ¡ç‰¹å®šçš„è¯·æ±‚æ ‡å‡†åŒ–
    if (this.providerType === 'qwen') {
      return this.normalizeQwenRequest(normalized);
    }

    return normalized;
  }

  private normalizeQwenRequest(request: UnknownObject): UnknownObject {
    // Qwenç‰¹å®šçš„è¯·æ±‚æ ‡å‡†åŒ–
    const allowedKeys = [
      'model', 'messages', 'input', 'parameters',
      'tools', 'stream', 'response_format', 'user', 'metadata'
    ];

    const filtered: UnknownObject = {};
    for (const key of allowedKeys) {
      if (key in request) {
        filtered[key] = request[key];
      }
    }

    return filtered;
  }

  private normalizeResponse(httpResponse: any, startTime: number): ProviderResponse {
    const processingTime = Date.now() - startTime;

    return {
      data: httpResponse.data,
      status: httpResponse.status,
      headers: httpResponse.headers,
      metadata: {
        requestId: this.id,
        processingTime,
        providerType: this.providerType,
        model: httpResponse.data?.model,
        usage: httpResponse.data?.usage
      }
    };
  }

  private createAuthProvider(credentials: ApiKeyAuth | OAuthAuth): IAuthProvider {
    switch (credentials.type) {
      case 'apikey':
        return new ApiKeyAuth(credentials);
      case 'oauth':
        return new OAuthAuth(credentials, this.providerType);
      default:
        throw new Error(`Unsupported auth type: ${(credentials as any).type}`);
    }
  }
}
```

## ğŸ”§ é…ç½®ç¤ºä¾‹

### GLMé…ç½® (é…ç½®é©±åŠ¨ï¼Œæ— éœ€ä»£ç )

```json
{
  "type": "openai-standard",
  "config": {
    "providerType": "glm",
    "baseUrl": "https://open.bigmodel.cn/api/paas/v4",
    "auth": {
      "type": "apikey",
      "apiKey": "your-glm-api-key"
    },
    "overrides": {
      "defaultModel": "glm-4"
    }
  }
}
```

### Qwené…ç½® (OAuthè®¤è¯)

```json
{
  "type": "openai-standard",
  "config": {
    "providerType": "qwen",
    "auth": {
      "type": "oauth",
      "clientId": "your-client-id",
      "tokenUrl": "https://chat.qwen.ai/api/v1/oauth2/token",
      "deviceCodeUrl": "https://chat.qwen.ai/api/v1/oauth2/device/code",
      "tokenFile": "./qwen-token.json"
    }
  }
}
```

### OpenAIé…ç½®

```json
{
  "type": "openai-standard",
  "config": {
    "providerType": "openai",
    "auth": {
      "type": "apikey",
      "apiKey": "sk-your-openai-key"
    }
  }
}
```

## ğŸ”„ æ¥å£é€æ˜æ€§ä¿è¯

### ç°æœ‰ç”¨æ³• (å®Œå…¨ä¸å˜)

```typescript
// æ—§ä»£ç è·¯å¾„å’Œç”¨æ³•ä¿æŒä¸å˜
import { GLMHTTPProvider } from './glm-http-provider.js';

const glmProvider = new GLMHTTPProvider(config, dependencies);
await glmProvider.initialize();
const response = await glmProvider.processIncoming(request);
```

### æ–°ç‰ˆæœ¬ç”¨æ³• (æ¥å£ä¸€è‡´)

```typescript
// æ–°ä»£ç è·¯å¾„ï¼Œä½†æ¥å£å®Œå…¨ä¸€è‡´
import { OpenAIStandard } from './v2/core/openai-standard.js';

const glmProvider = new OpenAIStandard(config, dependencies);
await glmProvider.initialize();
const response = await glmProvider.processIncoming(request);
```

## ğŸš€ å®æ–½è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºv2åŸºç¡€ç»“æ„ (1å¤©)
1. åˆ›å»ºv2ç›®å½•å’Œæ ¸å¿ƒæ–‡ä»¶
2. å®ç°ç»Ÿä¸€OpenAI Provider
3. å®ç°è®¤è¯æ¨¡å—
4. åˆ›å»ºæœåŠ¡é…ç½®æ¡£æ¡ˆ

### ç¬¬äºŒé˜¶æ®µï¼šGLMé…ç½®æµ‹è¯• (1å¤©)
1. åˆ›å»ºGLMé…ç½®æ–‡ä»¶
2. æµ‹è¯•GLMæœåŠ¡æ¥å…¥
3. éªŒè¯ä¸æ—§ç‰ˆæœ¬åŠŸèƒ½ä¸€è‡´æ€§
4. æ€§èƒ½å¯¹æ¯”æµ‹è¯•

### ç¬¬ä¸‰é˜¶æ®µï¼šæ‰©å±•å…¶ä»–æœåŠ¡ (2å¤©)
1. æµ‹è¯•Qwen OAuthè®¤è¯
2. æµ‹è¯•OpenAI API
3. æµ‹è¯•iFlowæœåŠ¡
4. æµ‹è¯•LM Studioæœ¬åœ°æœåŠ¡

### ç¬¬å››é˜¶æ®µï¼šé›†æˆå’Œä¼˜åŒ– (2å¤©)
1. Providerå·¥å‚å®ç°
2. é…ç½®å…¼å®¹æ€§å¤„ç†
3. é”™è¯¯å¤„ç†å’Œæ—¥å¿—å®Œå–„
4. æ–‡æ¡£æ›´æ–°

## ğŸ“ˆ é¢„æœŸæ”¶ç›Š

- **é›¶é£é™©è¿ç§»** - æ—§ä»£ç å®Œå…¨ä¸å˜ï¼Œæ–°ä»£ç ç‹¬ç«‹è¿è¡Œ
- **ä»£ç å‡å°‘90%** - å¤šä¸ªProvideråˆå¹¶ä¸º1ä¸ªç»Ÿä¸€å®ç°
- **é…ç½®é©±åŠ¨** - GLMç­‰æœåŠ¡åªéœ€é…ç½®ï¼Œæ— éœ€ä»£ç 
- **ç»´æŠ¤ç®€åŒ–** - åªéœ€ç»´æŠ¤ä¸€ä¸ªProviderå®ç°
- **æ¥å£é€æ˜** - æ–°æ—§ç‰ˆæœ¬æ¥å£å®Œå…¨ä¸€è‡´

---

**è¿™ä¸ªæœ€ç»ˆè®¾è®¡æ˜¯å¦æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼Ÿä¿æŒæ—§ä»£ç ä¸å˜ï¼Œæ–°å¢v2è·¯å¾„ï¼ŒGLMé€šè¿‡é…ç½®å³å¯ä½¿ç”¨ã€‚**