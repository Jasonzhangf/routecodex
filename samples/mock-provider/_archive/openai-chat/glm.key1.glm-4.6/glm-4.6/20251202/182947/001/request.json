{
  "endpoint": "/v1/chat/completions",
  "stage": "provider-request",
  "requestId": "req_req-v2-1764671387484-wolqkr087",
  "timestamp": 1764671387485,
  "data": {
    "meta": {
      "stage": "provider-request",
      "version": "0.85.0",
      "buildTime": "2025-12-02T10:29:47.485Z"
    },
    "url": "https://open.bigmodel.cn/api/coding/paas/v4/chat/completions",
    "headers": {
      "Content-Type": "application/json",
      "User-Agent": "RouteCodex/2.0",
      "Authorization": "Bearer****PvttZB",
      "Accept": "application/json"
    },
    "body": {
      "messages": [
        {
          "role": "system",
          "content": "You are Claude Code, Anthropic's official CLI for Claude."
        },
        {
          "role": "system",
          "content": "Summarize this coding conversation in under 50 characters.\nCapture the main task, key files, problems addressed, and current status."
        },
        {
          "role": "user",
          "content": "Please write a 5-10 word title for the following conversation:\n\nUser: Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.\n\nUser: <command-name>/clear</command-name>\n            <command-message>clear</command-message>\n            <command-args></command-args>\n\nUser: <local-command-stdout></local-command-stdout>\n\nUser: 列出本地目录\n\nUser: [Request interrupted by user]\n\nUser: 列出本地目录\n\nUser: [Request interrupted by user]\n\nUser: 列出本地目录\n\nUser: [Request interrupted by user]\n\nUser: 列出本地目录\n\nUser: [Request interrupted by user]\n\nUser: 列出本地目录\n\nUser: [Request interrupted by user]\n\nUser: 列出本地目录\n\nUser: [Request interrupted by user]\n\nUser: 列出本地目录\n\nClaude: The Codex-For.ME service is available, but you have reached the request limit. Please try again after 1 hour or contact support to raise your limits.\n\nUser: 列出本地目录\n\nUser: [Request interrupted by user]\n\nRespond with the title for the conversation and nothing else."
        }
      ],
      "model": "glm-4.6",
      "max_tokens": 32000,
      "stream": false
    }
  },
  "reqId": "openai-chat-glm.key1.glm-4.6-glm-4.6-20251202T182947-001",
  "entryEndpoint": "/v1/chat/completions"
}