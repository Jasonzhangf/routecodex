{
  "meta": {
    "stage": "provider-response",
    "version": "0.89.253",
    "buildTime": "2025-12-23T12:44:15.900Z",
    "entryEndpoint": "/v1/responses",
    "clientRequestId": "openai-responses-unknown-unknown-20251223T204405869-048"
  },
  "url": "https://open.bigmodel.cn/api/coding/paas/v4/chat/completions",
  "headers": {
    "Content-Type": "application/json",
    "User-Agent": "codex_cli_rs/0.77.0 (Mac OS 15.7.3; arm64) iTerm.app/3.6.5",
    "Authorization": "Bearer****PvttZB",
    "Accept": "text/event-stream",
    "originator": "codex_cli_rs",
    "conversation_id": "019b4b1a-4a77-7be2-aa70-af43a98b8165",
    "session_id": "019b4b1a-4a77-7be2-aa70-af43a98b8165"
  },
  "body": {
    "data": {
      "choices": [
        {
          "finish_reason": "tool_calls",
          "index": 0,
          "message": {
            "content": "",
            "reasoning_content": "Patch syntax issue. I need to properly format it. Let me try again with correct format.",
            "role": "assistant",
            "tool_calls": [
              {
                "function": {
                  "arguments": "{\"input\":\"*** Begin Patch\\n*** Update File: /Users/fanzhang/Documents/github/webauto/apps/floating-panel/src/main/index.mts\\n@@\\nfunction flushPendingMessages() {\\n-  log(`flushPendingMessages called: win=${!!win}, visible=${win?.isVisible()}, pendingEvents=${pendingEvents.length}, pendingStatus=${!!pendingStatus}`);\\n-  \\n   if (!win || !win.isVisible()) {\\n-    log('ERROR: No window to send messages to');\\n     return;\\n   }\\n   \\n   for (const event of pendingEvents) {\\n-    log(`Sending pending event: ${event.topic || 'unknown'}`);\\n     try {\\n       win.webContents.send('bus:event', event);\\n     } catch (err) {\\n@@\\n   if (pendingStatus) {\\n-    log(`Sending pending status: ${JSON.stringify(pendingStatus)}`);\\n     try {\\n       win.webContents.send('bus:status', pendingStatus);\\n-      log(`Successfully sent status: ${JSON.stringify(pendingStatus)}`);\\n     } catch (err) {\\n       log(`ERROR sending status: ${err}`);\\n     }\\n     pendingStatus = null;\\n   }\\n-  \\n-  log('All pending messages flushed');\\n }\\n*** End Patch\",\"patch\":\"*** Begin Patch\\n*** Update File: /Users/fanzhang/Documents/github/webauto/apps/floating-panel/src/main/index.mts\\n@@\\nfunction flushPendingMessages() {\\n-  log(`flushPendingMessages called: win=${!!win}, visible=${win?.isVisible()}, pendingEvents=${pendingEvents.length}, pendingStatus=${!!pendingStatus}`);\\n-  \\n   if (!win || !win.isVisible()) {\\n-    log('ERROR: No window to send messages to');\\n     return;\\n   }\\n   \\n   for (const event of pendingEvents) {\\n-    log(`Sending pending event: ${event.topic || 'unknown'}`);\\n     try {\\n       win.webContents.send('bus:event', event);\\n     } catch (err) {\\n@@\\n   if (pendingStatus) {\\n-    log(`Sending pending status: ${JSON.stringify(pendingStatus)}`);\\n     try {\\n       win.webContents.send('bus:status', pendingStatus);\\n-      log(`Successfully sent status: ${JSON.stringify(pendingStatus)}`);\\n     } catch (err) {\\n       log(`ERROR sending status: ${err}`);\\n     }\\n     pendingStatus = null;\\n   }\\n-  \\n-  log('All pending messages flushed');\\n }\\n*** End Patch\"}",
                  "name": "apply_patch"
                },
                "id": "call_-8042201018329219343",
                "index": 0,
                "type": "function"
              }
            ]
          }
        }
      ],
      "created": 1766493855,
      "id": "20251223204406b02d92f206a848e6",
      "model": "glm-4.7",
      "object": "chat.completion",
      "request_id": "20251223204406b02d92f206a848e6",
      "usage": {
        "completion_tokens": 527,
        "prompt_tokens": 37941,
        "prompt_tokens_details": {
          "cached_tokens": 34542
        },
        "total_tokens": 38468
      }
    },
    "status": 200,
    "statusText": "OK",
    "headers": {
      "connection": "keep-alive",
      "content-encoding": "gzip",
      "content-type": "application/json; charset=UTF-8",
      "date": "Tue, 23 Dec 2025 12:44:15 GMT",
      "set-cookie": "acw_tc=0ae5a7dc17664938460892371e7e3ca08ac5f613e14bc9633ac1d1fe5eab4a;path=/;HttpOnly;Max-Age=1800",
      "strict-transport-security": "max-age=31536000; includeSubDomains",
      "transfer-encoding": "chunked",
      "vary": "Accept-Encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers, Origin, Access-Control-Request-Method, Access-Control-Request-Headers",
      "x-log-id": "20251223204406b02d92f206a848e6"
    },
    "url": "https://open.bigmodel.cn/api/coding/paas/v4/chat/completions"
  },
  "reqId": "openai-responses-unknown-unknown-20251225T092025-141"
}