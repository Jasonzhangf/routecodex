{
  "testRequests": [
    {
      "id": "default-request-001",
      "category": "default",
      "description": "Standard general purpose request",
      "data": {
        "model": "llama3-8b-instruct",
        "messages": [
          {
            "role": "user",
            "content": "Hello, can you help me with a simple question?"
          }
        ],
        "temperature": 0.7,
        "max_tokens": 1000
      },
      "expectedRoute": {
        "category": "default",
        "providers": ["lmstudio", "qwen"],
        "models": ["llama3-8b-instruct", "qwen3-coder-plus"]
      }
    },
    {
      "id": "longcontext-request-001",
      "category": "longcontext",
      "description": "Long text processing request",
      "data": {
        "model": "qwen3-coder-plus",
        "messages": [
          {
            "role": "user",
            "content": "I need to analyze a very long document with over 20000 tokens. Please help me process this comprehensive text that contains detailed information about multiple topics and requires deep analysis of the content structure and relationships between different sections."
          }
        ],
        "temperature": 0.7,
        "max_tokens": 32768
      },
      "expectedRoute": {
        "category": "longcontext",
        "providers": ["qwen"],
        "models": ["qwen3-coder-plus"]
      }
    },
    {
      "id": "thinking-request-001",
      "category": "thinking",
      "description": "Complex reasoning request",
      "data": {
        "model": "llama3-70b-instruct",
        "messages": [
          {
            "role": "user",
            "content": "Please analyze and compare the philosophical differences between Kant's categorical imperative and utilitarianism. Explain how these frameworks would approach the trolley problem and provide a detailed evaluation of their strengths and weaknesses."
          }
        ],
        "temperature": 0.7,
        "max_tokens": 2000
      },
      "expectedRoute": {
        "category": "thinking",
        "providers": ["lmstudio", "qwen"],
        "models": ["llama3-70b-instruct", "qwen3-coder-plus"]
      }
    },
    {
      "id": "coding-request-001",
      "category": "coding",
      "description": "Code generation request",
      "data": {
        "model": "qwen3-coder-plus",
        "messages": [
          {
            "role": "user",
            "content": "Please implement a binary search algorithm in Python and explain its time complexity. Also provide a test case to verify the implementation works correctly."
          }
        ],
        "temperature": 0.3,
        "max_tokens": 1500
      },
      "expectedRoute": {
        "category": "coding",
        "providers": ["lmstudio", "qwen"],
        "models": ["llama3-8b-instruct", "qwen3-coder-plus"]
      }
    },
    {
      "id": "websearch-request-001",
      "category": "websearch",
      "description": "Web search request",
      "data": {
        "model": "qwen3-coder-plus",
        "messages": [
          {
            "role": "user",
            "content": "What's the latest news about artificial intelligence developments today? Please search for recent breakthroughs in AI technology."
          }
        ],
        "temperature": 0.7,
        "max_tokens": 1000
      },
      "expectedRoute": {
        "category": "websearch",
        "providers": ["qwen"],
        "models": ["qwen3-coder-plus"]
      }
    },
    {
      "id": "vision-request-001",
      "category": "vision",
      "description": "Image processing request",
      "data": {
        "model": "llama3-8b-instruct",
        "messages": [
          {
            "role": "user",
            "content": "I have a screenshot of an error message. Can you help me analyze what this error means and suggest how to fix it? The image shows a JavaScript error in the browser console."
          }
        ],
        "temperature": 0.7,
        "max_tokens": 1000
      },
      "expectedRoute": {
        "category": "vision",
        "providers": ["lmstudio"],
        "models": ["llama3-8b-instruct"]
      }
    },
    {
      "id": "background-request-001",
      "category": "background",
      "description": "Background processing request",
      "data": {
        "model": "llama3-8b-instruct",
        "messages": [
          {
            "role": "user",
            "content": "Please process this large dataset in the background and generate a summary report. This is a batch processing task that doesn't require immediate results."
          }
        ],
        "temperature": 0.7,
        "max_tokens": 2000
      },
      "expectedRoute": {
        "category": "background",
        "providers": ["lmstudio"],
        "models": ["llama3-8b-instruct"]
      }
    }
  ]
}