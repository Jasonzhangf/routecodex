{
  "providers": {
    "glm": {
      "id": "glm",
      "type": "openai",
      "baseUrl": "https://open.bigmodel.cn/api/coding/paas/v4",
      "headers": {
        "Content-Type": "application/json"
      },
      "models": {
        "glm-4.6": {
          "maxContext": 200000,
          "maxTokens": 8192,
          "compatibility": {
            "type": "compatibility",
            "config": {
              "moduleType": "glm",
              "moduleConfig": {
                "thinking": {
                  "enabled": true,
                  "payload": {
                    "type": "enabled"
                  }
                },
                "policy": {
                  "preflight": true
                }
              }
            }
          }
        },
        "glm-4.5-air": {
          "maxContext": 128000,
          "maxTokens": 8192,
          "compatibility": {
            "type": "compatibility",
            "config": {
              "moduleType": "glm",
              "moduleConfig": {
                "thinking": {
                  "enabled": true,
                  "payload": {
                    "type": "enabled"
                  }
                },
                "policy": {
                  "preflight": true
                }
              }
            }
          }
        }
      },
      "providerType": "openai",
      "protocol": "openai-chat",
      "endpoint": "/chat/completions",
      "timeoutMs": 300000,
      "maxRetries": 3,
      "authCapabilities": {
        "required": [
          "apikey"
        ],
        "optional": [
          "oauth"
        ]
      },
      "compat": "glm"
    },
    "qwen": {
      "id": "qwen",
      "type": "openai",
      "baseUrl": "https://portal.qwen.ai/v1",
      "headers": {
        "Content-Type": "application/json"
      },
      "models": {
        "qwen3-coder-plus": {}
      },
      "providerType": "openai",
      "protocol": "openai-chat",
      "endpoint": "/chat/completions",
      "timeoutMs": 300000,
      "maxRetries": 3,
      "authCapabilities": {
        "required": [
          "oauth"
        ],
        "optional": [
          "apikey"
        ]
      },
      "compat": "qwen"
    },
    "kimi": {
      "id": "kimi",
      "type": "openai",
      "baseUrl": "https://api.kimi.com/coding/v1",
      "headers": {
        "Content-Type": "application/json"
      },
      "models": {
        "kimi-for-coding": {}
      },
      "providerType": "openai",
      "protocol": "openai-chat",
      "endpoint": "/chat/completions",
      "timeoutMs": 300000,
      "maxRetries": 3,
      "authCapabilities": {
        "required": [
          "apikey"
        ],
        "optional": [
          "oauth"
        ]
      },
      "compat": "none"
    },
    "iflow": {
      "id": "iflow",
      "type": "iflow",
      "baseUrl": "https://apis.iflow.cn/v1",
      "headers": {},
      "models": {
        "tstars2.0": {},
        "qwen3-coder-plus": {},
        "qwen3-coder": {},
        "qwen3-max": {},
        "qwen3-vl-plus": {},
        "qwen3-max-preview": {},
        "kimi-k2-0905": {},
        "glm-4.6": {},
        "kimi-k2": {},
        "kimi-k2-thinking": {},
        "deepseek-v3.2": {},
        "deepseek-v3.1": {},
        "deepseek-r1": {},
        "deepseek-v3": {},
        "qwen3-32b": {},
        "qwen3-235b-a22b-thinking-2507": {},
        "qwen3-235b-a22b-instruct": {},
        "qwen3-235b": {},
        "minimax-m2": {}
      },
      "providerType": "iflow",
      "compat": "iflow"
    }
  },
  "keyVault": {
    "glm": {
      "key1": {
        "type": "apikey",
        "value": "6484fedc2cc9429e892dde8abf4c0bb8.es5PmJPf8XPvttZB",
        "enabled": true
      }
    },
    "kimi": {
      "key1": {
        "type": "apikey",
        "value": "${KIMI_API_KEY}",
        "enabled": true
      }
    }
  },
  "routing": {
    "default": [
      "glm.glm-4.6",
      "qwen.qwen3-coder-plus",
      "iflow.kimi-k2-thinking",
      "iflow.minimax-m2"
    ],
    "anthropic": [
      "glm.glm-4.6"
    ],
    "coding": [],
    "longcontext": [],
    "tools": [],
    "thinking": [],
    "vision": [
      "iflow.qwen3-vl-plus"
    ],
    "websearch": [],
    "background": []
  },
  "routeMeta": {
    "glm.glm-4.6": {
      "providerId": "glm",
      "modelId": "glm-4.6"
    },
    "qwen.qwen3-coder-plus": {
      "providerId": "qwen",
      "modelId": "qwen3-coder-plus"
    },
    "iflow.kimi-k2-thinking": {
      "providerId": "iflow",
      "modelId": "kimi-k2-thinking"
    },
    "iflow.minimax-m2": {
      "providerId": "iflow",
      "modelId": "minimax-m2"
    },
    "iflow.qwen3-vl-plus": {
      "providerId": "iflow",
      "modelId": "qwen3-vl-plus"
    }
  },
  "_metadata": {
    "version": "0.1.0",
    "builtAt": 1763987664466,
    "keyDimension": "perKey"
  },
  "conversionV3": {
    "pipelineConfig": {
      "pipelineConfigVersion": "1.0.0",
      "generatedAt": "2025-11-24T12:34:24.465Z",
      "pipelines": [
        {
          "id": "pipeline-openai-chat",
          "name": "OpenAI Chat Request Pipeline",
          "entryEndpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/chat/completions"
          ],
          "providerProtocols": [
            "openai-chat"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "chat-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "chat-input-node",
              "kind": "input",
              "implementation": "chat-input"
            },
            {
              "id": "chat-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "chat-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "chat-request-compat-glm",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "glm",
                  "direction": "request",
                  "providerMatch": [
                    "glm"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-request-compat-qwen",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "qwen",
                  "direction": "request",
                  "providerMatch": [
                    "qwen"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-output-node",
              "kind": "output",
              "implementation": "openai-output"
            },
            {
              "id": "chat-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-openai-chat-response",
          "name": "OpenAI Chat Response Pipeline",
          "entryEndpoints": [
            "/v1/chat/completions#response",
            "/v1/completions#response",
            "/chat/completions#response"
          ],
          "processMode": "chat",
          "nodes": [
            {
              "id": "chat-response-input-node",
              "kind": "input",
              "implementation": "openai-response-input"
            },
            {
              "id": "chat-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "chat-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "chat-response-response-compat-glm",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "glm",
                  "direction": "response",
                  "providerMatch": [
                    "glm"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-response-response-compat-qwen",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "qwen",
                  "direction": "response",
                  "providerMatch": [
                    "qwen"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-response-output-node",
              "kind": "output",
              "implementation": "openai-output"
            },
            {
              "id": "chat-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-responses",
          "name": "OpenAI Responses Request Pipeline",
          "entryEndpoints": [
            "/v1/responses",
            "/responses"
          ],
          "providerProtocols": [
            "openai-responses"
          ],
          "processMode": "chat",
          "streaming": "always",
          "nodes": [
            {
              "id": "responses-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "responses-input-node",
              "kind": "input",
              "implementation": "responses-input"
            },
            {
              "id": "responses-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "responses-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "responses-output-node",
              "kind": "output",
              "implementation": "responses-output"
            },
            {
              "id": "responses-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-responses-response",
          "name": "OpenAI Responses Response Pipeline",
          "entryEndpoints": [
            "/v1/responses#response",
            "/responses#response"
          ],
          "processMode": "chat",
          "nodes": [
            {
              "id": "responses-response-input-node",
              "kind": "input",
              "implementation": "responses-response-input"
            },
            {
              "id": "responses-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "responses-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "responses-response-output-node",
              "kind": "output",
              "implementation": "responses-output"
            },
            {
              "id": "responses-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-anthropic",
          "name": "Anthropic Messages Request Pipeline",
          "entryEndpoints": [
            "/v1/messages",
            "/messages"
          ],
          "providerProtocols": [
            "anthropic-messages"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "anthropic-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "anthropic-input-node",
              "kind": "input",
              "implementation": "anthropic-input"
            },
            {
              "id": "anthropic-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "anthropic-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "anthropic-output-node",
              "kind": "output",
              "implementation": "anthropic-output"
            },
            {
              "id": "anthropic-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-anthropic-response",
          "name": "Anthropic Messages Response Pipeline",
          "entryEndpoints": [
            "/v1/messages#response",
            "/messages#response"
          ],
          "processMode": "chat",
          "nodes": [
            {
              "id": "anthropic-response-input-node",
              "kind": "input",
              "implementation": "anthropic-response-input"
            },
            {
              "id": "anthropic-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "anthropic-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "anthropic-response-output-node",
              "kind": "output",
              "implementation": "anthropic-output"
            },
            {
              "id": "anthropic-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-chat-to-responses",
          "name": "OpenAI Chat Request Pipeline → OpenAI Responses Request Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/chat/completions"
          ],
          "providerProtocols": [
            "openai-responses"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "chat-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "chat-input-node",
              "kind": "input",
              "implementation": "chat-input"
            },
            {
              "id": "chat-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "chat-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "responses-output-node",
              "kind": "output",
              "implementation": "responses-output"
            },
            {
              "id": "responses-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-responses-to-chat-response",
          "name": "OpenAI Responses Response Pipeline → OpenAI Chat Response Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/chat/completions#response",
            "/v1/completions#response",
            "/chat/completions#response"
          ],
          "providerProtocols": [
            "openai-responses"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "responses-response-input-node",
              "kind": "input",
              "implementation": "responses-response-input"
            },
            {
              "id": "responses-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "responses-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "chat-response-output-node",
              "kind": "output",
              "implementation": "openai-output"
            },
            {
              "id": "chat-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-chat-to-anthropic",
          "name": "OpenAI Chat Request Pipeline → Anthropic Messages Request Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/chat/completions"
          ],
          "providerProtocols": [
            "anthropic-messages"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "chat-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "chat-input-node",
              "kind": "input",
              "implementation": "chat-input"
            },
            {
              "id": "chat-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "chat-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "anthropic-output-node",
              "kind": "output",
              "implementation": "anthropic-output"
            },
            {
              "id": "anthropic-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-anthropic-to-chat-response",
          "name": "Anthropic Messages Response Pipeline → OpenAI Chat Response Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/chat/completions#response",
            "/v1/completions#response",
            "/chat/completions#response"
          ],
          "providerProtocols": [
            "anthropic-messages"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "anthropic-response-input-node",
              "kind": "input",
              "implementation": "anthropic-response-input"
            },
            {
              "id": "anthropic-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "anthropic-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "chat-response-output-node",
              "kind": "output",
              "implementation": "openai-output"
            },
            {
              "id": "chat-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-responses-to-chat",
          "name": "OpenAI Responses Request Pipeline → OpenAI Chat Request Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/responses",
            "/responses"
          ],
          "providerProtocols": [
            "openai-chat"
          ],
          "processMode": "chat",
          "streaming": "always",
          "nodes": [
            {
              "id": "responses-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "responses-input-node",
              "kind": "input",
              "implementation": "responses-input"
            },
            {
              "id": "responses-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "responses-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "responses-request-compat-glm",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "glm",
                  "direction": "request",
                  "providerMatch": [
                    "glm"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "responses-request-compat-qwen",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "qwen",
                  "direction": "request",
                  "providerMatch": [
                    "qwen"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-output-node",
              "kind": "output",
              "implementation": "openai-output"
            },
            {
              "id": "chat-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-chat-to-responses-response",
          "name": "OpenAI Chat Response Pipeline → OpenAI Responses Response Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/responses#response",
            "/responses#response"
          ],
          "providerProtocols": [
            "openai-chat"
          ],
          "processMode": "chat",
          "streaming": "always",
          "nodes": [
            {
              "id": "chat-response-input-node",
              "kind": "input",
              "implementation": "openai-response-input"
            },
            {
              "id": "chat-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "chat-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "chat-response-response-compat-glm",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "glm",
                  "direction": "response",
                  "providerMatch": [
                    "glm"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-response-response-compat-qwen",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "qwen",
                  "direction": "response",
                  "providerMatch": [
                    "qwen"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "responses-response-output-node",
              "kind": "output",
              "implementation": "responses-output"
            },
            {
              "id": "responses-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-responses-to-anthropic",
          "name": "OpenAI Responses Request Pipeline → Anthropic Messages Request Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/responses",
            "/responses"
          ],
          "providerProtocols": [
            "anthropic-messages"
          ],
          "processMode": "chat",
          "streaming": "always",
          "nodes": [
            {
              "id": "responses-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "responses-input-node",
              "kind": "input",
              "implementation": "responses-input"
            },
            {
              "id": "responses-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "responses-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "anthropic-output-node",
              "kind": "output",
              "implementation": "anthropic-output"
            },
            {
              "id": "anthropic-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-anthropic-to-responses-response",
          "name": "Anthropic Messages Response Pipeline → OpenAI Responses Response Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/responses#response",
            "/responses#response"
          ],
          "providerProtocols": [
            "anthropic-messages"
          ],
          "processMode": "chat",
          "streaming": "always",
          "nodes": [
            {
              "id": "anthropic-response-input-node",
              "kind": "input",
              "implementation": "anthropic-response-input"
            },
            {
              "id": "anthropic-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "anthropic-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "responses-response-output-node",
              "kind": "output",
              "implementation": "responses-output"
            },
            {
              "id": "responses-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-anthropic-to-chat",
          "name": "Anthropic Messages Request Pipeline → OpenAI Chat Request Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/messages",
            "/messages"
          ],
          "providerProtocols": [
            "openai-chat"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "anthropic-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "anthropic-input-node",
              "kind": "input",
              "implementation": "anthropic-input"
            },
            {
              "id": "anthropic-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "anthropic-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "anthropic-request-compat-glm",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "glm",
                  "direction": "request",
                  "providerMatch": [
                    "glm"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "anthropic-request-compat-qwen",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "qwen",
                  "direction": "request",
                  "providerMatch": [
                    "qwen"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-output-node",
              "kind": "output",
              "implementation": "openai-output"
            },
            {
              "id": "chat-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-chat-to-anthropic-response",
          "name": "OpenAI Chat Response Pipeline → Anthropic Messages Response Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/messages#response",
            "/messages#response"
          ],
          "providerProtocols": [
            "openai-chat"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "chat-response-input-node",
              "kind": "input",
              "implementation": "openai-response-input"
            },
            {
              "id": "chat-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "chat-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "chat-response-response-compat-glm",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "glm",
                  "direction": "response",
                  "providerMatch": [
                    "glm"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "chat-response-response-compat-qwen",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "qwen",
                  "direction": "response",
                  "providerMatch": [
                    "qwen"
                  ],
                  "protocolMatch": [
                    "openai-chat"
                  ]
                }
              }
            },
            {
              "id": "anthropic-response-output-node",
              "kind": "output",
              "implementation": "anthropic-output"
            },
            {
              "id": "anthropic-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-anthropic-to-responses",
          "name": "Anthropic Messages Request Pipeline → OpenAI Responses Request Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/messages",
            "/messages"
          ],
          "providerProtocols": [
            "openai-responses"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "anthropic-sse-input",
              "kind": "sse-input",
              "implementation": "sse-input"
            },
            {
              "id": "anthropic-input-node",
              "kind": "input",
              "implementation": "anthropic-input"
            },
            {
              "id": "anthropic-process-node",
              "kind": "process",
              "implementation": "chat-process"
            },
            {
              "id": "anthropic-request-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "request"
                }
              }
            },
            {
              "id": "responses-output-node",
              "kind": "output",
              "implementation": "responses-output"
            },
            {
              "id": "responses-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        },
        {
          "id": "pipeline-responses-to-anthropic-response",
          "name": "OpenAI Responses Response Pipeline → Anthropic Messages Response Pipeline (Bridge)",
          "entryEndpoints": [
            "/v1/messages#response",
            "/messages#response"
          ],
          "providerProtocols": [
            "openai-responses"
          ],
          "processMode": "chat",
          "streaming": "never",
          "nodes": [
            {
              "id": "responses-response-input-node",
              "kind": "input",
              "implementation": "responses-response-input"
            },
            {
              "id": "responses-response-process-node",
              "kind": "process",
              "implementation": "response-process"
            },
            {
              "id": "responses-response-response-compat-default",
              "kind": "process",
              "implementation": "compatibility-process",
              "options": {
                "compatibility": {
                  "profile": "default",
                  "direction": "response"
                }
              }
            },
            {
              "id": "anthropic-response-output-node",
              "kind": "output",
              "implementation": "anthropic-output"
            },
            {
              "id": "anthropic-response-sse-output",
              "kind": "sse-output",
              "implementation": "sse-output"
            }
          ]
        }
      ]
    }
  },
  "pipeline_assembler": {
    "config": {
      "pipelines": [
        {
          "id": "glm_key1.glm-4.6",
          "provider": {
            "type": "openai-http-provider"
          },
          "modules": {
            "provider": {
              "type": "openai-http-provider",
              "config": {
                "providerId": "glm",
                "type": "openai-http-provider",
                "providerType": "openai",
                "protocol": "openai-chat",
                "baseUrl": "https://open.bigmodel.cn/api/coding/paas/v4",
                "endpoint": "/chat/completions",
                "timeoutMs": 300000,
                "maxRetries": 3,
                "headers": {
                  "Content-Type": "application/json"
                },
                "authCapabilities": {
                  "required": [
                    "apikey"
                  ],
                  "optional": [
                    "oauth"
                  ]
                },
                "modelId": "glm-4.6"
              }
            },
            "compatibility": {
              "type": "glm-compatibility",
              "config": {}
            },
            "llmSwitch": {
              "type": "llmswitch-conversion-router",
              "config": {
                "process": "chat"
              }
            },
            "workflow": {
              "type": "streaming-control",
              "config": {}
            }
          },
          "settings": {
            "debugEnabled": true
          },
          "model": {
            "actualModelId": "glm-4.6"
          },
          "authRef": {
            "mode": "perKey",
            "providerId": "glm",
            "keyId": "key1"
          }
        },
        {
          "id": "qwen.qwen3-coder-plus",
          "provider": {
            "type": "openai-http-provider"
          },
          "modules": {
            "provider": {
              "type": "openai-http-provider",
              "config": {
                "providerId": "qwen",
                "type": "openai-http-provider",
                "providerType": "openai",
                "protocol": "openai-chat",
                "baseUrl": "https://portal.qwen.ai/v1",
                "endpoint": "/chat/completions",
                "timeoutMs": 300000,
                "maxRetries": 3,
                "headers": {
                  "Content-Type": "application/json"
                },
                "authCapabilities": {
                  "required": [
                    "oauth"
                  ],
                  "optional": [
                    "apikey"
                  ]
                },
                "modelId": "qwen3-coder-plus"
              }
            },
            "compatibility": {
              "type": "qwen-compatibility",
              "config": {}
            },
            "llmSwitch": {
              "type": "llmswitch-conversion-router",
              "config": {
                "process": "chat"
              }
            },
            "workflow": {
              "type": "streaming-control",
              "config": {}
            }
          },
          "settings": {
            "debugEnabled": true
          },
          "model": {
            "actualModelId": "qwen3-coder-plus"
          },
          "authRef": {
            "mode": "perPipeline",
            "providerId": "qwen"
          }
        },
        {
          "id": "iflow.kimi-k2-thinking",
          "provider": {
            "type": "iflow"
          },
          "modules": {
            "provider": {
              "type": "iflow",
              "config": {
                "providerId": "iflow",
                "type": "iflow",
                "providerType": "iflow",
                "baseUrl": "https://apis.iflow.cn/v1",
                "headers": {},
                "modelId": "kimi-k2-thinking"
              }
            },
            "compatibility": {
              "type": "iflow-compatibility",
              "config": {}
            },
            "llmSwitch": {
              "type": "llmswitch-conversion-router",
              "config": {
                "process": "chat"
              }
            },
            "workflow": {
              "type": "streaming-control",
              "config": {}
            }
          },
          "settings": {
            "debugEnabled": true
          },
          "model": {
            "actualModelId": "kimi-k2-thinking"
          },
          "authRef": {
            "mode": "perPipeline",
            "providerId": "iflow"
          }
        },
        {
          "id": "iflow.minimax-m2",
          "provider": {
            "type": "iflow"
          },
          "modules": {
            "provider": {
              "type": "iflow",
              "config": {
                "providerId": "iflow",
                "type": "iflow",
                "providerType": "iflow",
                "baseUrl": "https://apis.iflow.cn/v1",
                "headers": {},
                "modelId": "minimax-m2"
              }
            },
            "compatibility": {
              "type": "iflow-compatibility",
              "config": {}
            },
            "llmSwitch": {
              "type": "llmswitch-conversion-router",
              "config": {
                "process": "chat"
              }
            },
            "workflow": {
              "type": "streaming-control",
              "config": {}
            }
          },
          "settings": {
            "debugEnabled": true
          },
          "model": {
            "actualModelId": "minimax-m2"
          },
          "authRef": {
            "mode": "perPipeline",
            "providerId": "iflow"
          }
        },
        {
          "id": "iflow.qwen3-vl-plus",
          "provider": {
            "type": "iflow"
          },
          "modules": {
            "provider": {
              "type": "iflow",
              "config": {
                "providerId": "iflow",
                "type": "iflow",
                "providerType": "iflow",
                "baseUrl": "https://apis.iflow.cn/v1",
                "headers": {},
                "modelId": "qwen3-vl-plus"
              }
            },
            "compatibility": {
              "type": "iflow-compatibility",
              "config": {}
            },
            "llmSwitch": {
              "type": "llmswitch-conversion-router",
              "config": {
                "process": "chat"
              }
            },
            "workflow": {
              "type": "streaming-control",
              "config": {}
            }
          },
          "settings": {
            "debugEnabled": true
          },
          "model": {
            "actualModelId": "qwen3-vl-plus"
          },
          "authRef": {
            "mode": "perPipeline",
            "providerId": "iflow"
          }
        }
      ],
      "routePools": {
        "default": [
          "glm_key1.glm-4.6",
          "qwen.qwen3-coder-plus",
          "iflow.kimi-k2-thinking",
          "iflow.minimax-m2"
        ],
        "anthropic": [
          "glm_key1.glm-4.6"
        ],
        "coding": [],
        "longcontext": [],
        "tools": [],
        "thinking": [],
        "vision": [
          "iflow.qwen3-vl-plus"
        ],
        "websearch": [],
        "background": []
      },
      "routeMeta": {
        "glm_key1.glm-4.6": {
          "providerId": "glm",
          "modelId": "glm-4.6",
          "keyId": "key1"
        },
        "qwen.qwen3-coder-plus": {
          "providerId": "qwen",
          "modelId": "qwen3-coder-plus"
        },
        "iflow.kimi-k2-thinking": {
          "providerId": "iflow",
          "modelId": "kimi-k2-thinking"
        },
        "iflow.minimax-m2": {
          "providerId": "iflow",
          "modelId": "minimax-m2"
        },
        "iflow.qwen3-vl-plus": {
          "providerId": "iflow",
          "modelId": "qwen3-vl-plus"
        }
      }
    }
  }
}